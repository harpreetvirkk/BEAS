{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import plotly.express as px\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genesis_train(file):\n",
    "    data = pd.read_csv(file)\n",
    "    del data['Unnamed: 32']\n",
    "    print('Number of datapoints in Training dataset: ',len(data))\n",
    "    X_train = data.iloc[:, 2:].values\n",
    "    y_train = data.iloc[:, 1].values\n",
    "    \n",
    "    test = pd.read_csv('./data/test.csv')\n",
    "    del test['Unnamed: 32']\n",
    "    print('Number of datapoints in Testing dataset: ',len(test))\n",
    "    X_test = test.iloc[:, 2:].values\n",
    "    y_test = test.iloc[:, 1].values\n",
    "\n",
    "    labelencoder = LabelEncoder()\n",
    "    y_train = labelencoder.fit_transform(y_train)\n",
    "    y_test = labelencoder.fit_transform(y_test)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(16, activation='relu', input_dim=30))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=100, epochs=5)\n",
    "\n",
    "    scores = model.evaluate(X_test, y_test)\n",
    "    print(\"Loss: \", scores[0])        #Loss\n",
    "    print(\"Accuracy: \", scores[1])    #Accuracy\n",
    "\n",
    "    #Saving Model\n",
    "    model.save(\"./weights/global1.h5\")\n",
    "    return len(data), scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_train(name,file, globalId):\n",
    "    data = pd.read_csv(file)\n",
    "    del data['Unnamed: 32']\n",
    "    X_train = data.iloc[:, 2:].values\n",
    "    y_train = data.iloc[:, 1].values\n",
    "    \n",
    "    test = pd.read_csv('./data/test.csv')\n",
    "    del test['Unnamed: 32']\n",
    "    print('Number of datapoints in Testing dataset: ',len(test))\n",
    "    X_test = test.iloc[:, 2:].values\n",
    "    y_test = test.iloc[:, 1].values\n",
    "\n",
    "    labelencoder = LabelEncoder()\n",
    "    y_train = labelencoder.fit_transform(y_train)\n",
    "    y_test = labelencoder.fit_transform(y_test)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(16, activation='relu', input_dim=30))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.load_weights(\"./weights/global\"+str(globalId)+\".h5\")\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=100, epochs=5)\n",
    "\n",
    "    scores = model.evaluate(X_test, y_test)\n",
    "    print(\"Loss: \", scores[0])        #Loss\n",
    "    print(\"Accuracy: \", scores[1])    #Accuracy\n",
    "\n",
    "    #Saving Model\n",
    "    model.save(\"./weights/\" + str(name) + \".h5\")\n",
    "    return len(data), float(scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### FedAvg ####\n",
    "\n",
    "def getDataLen(trainingDf):\n",
    "    n = 0\n",
    "    for w in trainingDf.iloc():\n",
    "        n += w.DataSize\n",
    "    print('Total number of data points after this round: ', n)\n",
    "    return n\n",
    "\n",
    "def assignWeights(trainingDf):\n",
    "    n = getDataLen(trainingDf)\n",
    "    trainingDf['Weightage'] = trainingDf['DataSize'].apply(lambda x: x/n)\n",
    "    return trainingDf, n\n",
    "    \n",
    "def scale(weight, scaler):\n",
    "    scaledWeights = []\n",
    "    for i in range(len(weight)):\n",
    "        scaledWeights.append(scaler * weight[i])\n",
    "    return scaledWeights\n",
    "\n",
    "def getScaledWeight(m, scaler):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, activation='relu', input_dim=30))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    fpath = \"./weights/\"+m+\".h5\"\n",
    "    model.load_weights(fpath)\n",
    "    weight = model.get_weights()\n",
    "    return scale(weight, scaler)\n",
    "\n",
    "def avgWeights(scaledWeights):\n",
    "    avg = list()\n",
    "    for weight_list_tuple in zip(*scaledWeights):\n",
    "        layer_mean = tf.math.reduce_sum(weight_list_tuple, axis=0)\n",
    "        avg.append(layer_mean)\n",
    "    return avg\n",
    "\n",
    "def FedAvg(trainingDict):\n",
    "    trainingDf = pd.DataFrame.from_dict(trainingDict, orient='index', columns=['DataSize', 'Accuracy']) \n",
    "    models = []\n",
    "    for i in trainingDict.keys():\n",
    "        if 'global' not in i:\n",
    "            models.append(i)\n",
    "    scaledWeights = []\n",
    "    trainingDf, dataLen = assignWeights(trainingDf)\n",
    "    for m in models:\n",
    "        scaledWeights.append(getScaledWeight(m, trainingDf.loc[m]['Weightage']))\n",
    "    fedAvgWeight = avgWeights(scaledWeights)\n",
    "    return fedAvgWeight, dataLen\n",
    "\n",
    "def saveModel(weights, n):\n",
    "    \n",
    "    test = pd.read_csv('./data/test.csv')\n",
    "    del test['Unnamed: 32']\n",
    "    print('Number of datapoints in Testing dataset: ',len(test))\n",
    "    X_test = test.iloc[:, 2:].values\n",
    "    y_test = test.iloc[:, 1].values\n",
    "\n",
    "    labelencoder = LabelEncoder()\n",
    "    y_test = labelencoder.fit_transform(y_test)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(16, activation='relu', input_dim=30))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.set_weights(weights)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    scores = model.evaluate(X_test, y_test)\n",
    "    print(\"Loss: \", scores[0])        #Loss\n",
    "    print(\"Accuracy: \", scores[1])    #Accuracy\n",
    "\n",
    "    #Saving Model\n",
    "    fpath = \"./weights/global\"+n+\".h5\"\n",
    "    model.save(fpath)\n",
    "    return float(scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genesis Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints in Training dataset:  20\n",
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 60.9700 - accuracy: 0.5500\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 40.5637 - accuracy: 0.5500\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 46.8709 - accuracy: 0.4500\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 45.9495 - accuracy: 0.6000\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 30.0596 - accuracy: 0.6000\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x13b3a73a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 9.9559 - accuracy: 0.7467\n",
      "Loss:  9.955900192260742\n",
      "Accuracy:  0.746666669845581\n"
     ]
    }
   ],
   "source": [
    "globalDict = dict()\n",
    "trainingDict = dict()\n",
    "trainingDict['global1'] = genesis_train('./data/genesis.csv')\n",
    "globalDict['global1'] = trainingDict['global1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three Local "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 37.8604 - accuracy: 0.4694\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 28.1710 - accuracy: 0.5510\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 20.6108 - accuracy: 0.5102\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 18.5762 - accuracy: 0.4286\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 25.1155 - accuracy: 0.3878\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x13b8d2ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6843 - accuracy: 0.7867\n",
      "Loss:  0.6843255758285522\n",
      "Accuracy:  0.7866666913032532\n",
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 23.3000 - accuracy: 0.5870\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.0637 - accuracy: 0.6522\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 23.6052 - accuracy: 0.7174\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.9176 - accuracy: 0.5000\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 16.6402 - accuracy: 0.6304\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x13b2d48b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.7082 - accuracy: 0.7867\n",
      "Loss:  0.7082008123397827\n",
      "Accuracy:  0.7866666913032532\n",
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 29.3018 - accuracy: 0.5682\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 26.8578 - accuracy: 0.6591\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.6480 - accuracy: 0.6364\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5137 - accuracy: 0.6136\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 23.6654 - accuracy: 0.5227\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x13bc5d3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6410 - accuracy: 0.8267\n",
      "Loss:  0.64097660779953\n",
      "Accuracy:  0.8266666531562805\n"
     ]
    }
   ],
   "source": [
    "trainingDict['A'] = local_train('A','./data/dataA.csv', 1)\n",
    "trainingDict['B'] = local_train('B','./data/dataB.csv', 1)\n",
    "trainingDict['C'] = local_train('C','./data/dataC.csv', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global1': (20, 0.746666669845581),\n",
       " 'A': (49, 0.7866666913032532),\n",
       " 'B': (46, 0.7866666913032532),\n",
       " 'C': (44, 0.8266666531562805)}"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of data points after this round:  159.0\n"
     ]
    }
   ],
   "source": [
    "NewGlobal, dataLen = FedAvg(trainingDict)\n",
    "# print(NewGlobal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints in Testing dataset:  75\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x13a78da60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.5066 - accuracy: 0.7867\n",
      "Loss:  0.5066019892692566\n",
      "Accuracy:  0.7866666913032532\n",
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 871us/step - loss: 10.7301 - accuracy: 0.5122\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.1331 - accuracy: 0.5854\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.5959 - accuracy: 0.7561\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.8872 - accuracy: 0.6098\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.7210 - accuracy: 0.6341\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x13cdffca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3.0816 - accuracy: 0.3867\n",
      "Loss:  3.0815844535827637\n",
      "Accuracy:  0.3866666555404663\n",
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.4808 - accuracy: 0.7222\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 852us/step - loss: 1.5539 - accuracy: 0.7778\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.9481 - accuracy: 0.8333\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 978us/step - loss: 7.5745 - accuracy: 0.4444\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 946us/step - loss: 10.1612 - accuracy: 0.3889\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x13cf74e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1.4230 - accuracy: 0.6800\n",
      "Loss:  1.4230366945266724\n",
      "Accuracy:  0.6800000071525574\n",
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.0911 - accuracy: 0.7609\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.0787 - accuracy: 0.5870\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9867 - accuracy: 0.6739\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.7053 - accuracy: 0.7391\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.7357 - accuracy: 0.6304\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x13d0ebc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1.3793 - accuracy: 0.6133\n",
      "Loss:  1.3793429136276245\n",
      "Accuracy:  0.6133333444595337\n",
      "Total number of data points after this round:  264.0\n"
     ]
    }
   ],
   "source": [
    "trainingDict = {}\n",
    "trainingDict['global2'] = (dataLen, saveModel(NewGlobal, '2'))\n",
    "globalDict['global2'] = trainingDict['global2']\n",
    "trainingDict['D'] = local_train('D','./data/dataD.csv', 2)\n",
    "trainingDict['E'] = local_train('E','./data/dataE.csv', 2)\n",
    "trainingDict['F'] = local_train('F','./data/dataF.csv', 2)\n",
    "NewGlobal, dataLen = FedAvg(trainingDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints in Testing dataset:  75\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x13b7f2f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6306 - accuracy: 0.5333\n",
      "Loss:  0.6305674314498901\n",
      "Accuracy:  0.5333333611488342\n",
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.6154\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1082 - accuracy: 0.5192\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6152 - accuracy: 0.5577\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5801 - accuracy: 0.6154\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8711 - accuracy: 0.5577\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x13a0e1670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.7049 - accuracy: 0.3600\n",
      "Loss:  0.7048617601394653\n",
      "Accuracy:  0.36000001430511475\n",
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7415 - accuracy: 0.4222\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5924 - accuracy: 0.8000\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5134 - accuracy: 0.8444\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8098 - accuracy: 0.7111\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5360 - accuracy: 0.7778\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x13bc5dee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6834 - accuracy: 0.7467\n",
      "Loss:  0.6833865642547607\n",
      "Accuracy:  0.746666669845581\n",
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 947us/step - loss: 0.7717 - accuracy: 0.7021\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 867us/step - loss: 0.7541 - accuracy: 0.6383\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 858us/step - loss: 0.6282 - accuracy: 0.6809\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.8723\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6160 - accuracy: 0.8298\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x13b8d2430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.8800\n",
      "Loss:  0.4546230137348175\n",
      "Accuracy:  0.8799999952316284\n",
      "Total number of data points after this round:  408.0\n"
     ]
    }
   ],
   "source": [
    "trainingDict = {}\n",
    "trainingDict['global3'] = (dataLen, saveModel(NewGlobal, '3'))\n",
    "globalDict['global3'] = trainingDict['global3']\n",
    "trainingDict['G'] = local_train('G','./data/dataG.csv', 3)\n",
    "trainingDict['H'] = local_train('H','./data/dataH.csv', 3)\n",
    "trainingDict['I'] = local_train('I','./data/dataI.csv', 3)\n",
    "NewGlobal, dataLen = FedAvg(trainingDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints in Testing dataset:  75\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x13b8d2280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6802 - accuracy: 0.8800\n",
      "Loss:  0.6801868677139282\n",
      "Accuracy:  0.8799999952316284\n",
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6796 - accuracy: 0.6538\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6585 - accuracy: 0.6346\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6507 - accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 970us/step - loss: 0.6174 - accuracy: 0.5577\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5981 - accuracy: 0.5192\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x13b8d2b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7061 - accuracy: 0.2533\n",
      "Loss:  0.7060788869857788\n",
      "Accuracy:  0.25333333015441895\n",
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.6780 - accuracy: 0.7778\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6671 - accuracy: 0.8000\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6636 - accuracy: 0.8222\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6549 - accuracy: 0.8222\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6557 - accuracy: 0.8222\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x13b44de50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.7467\n",
      "Loss:  0.6848666667938232\n",
      "Accuracy:  0.746666669845581\n",
      "Total number of data points after this round:  505.0\n"
     ]
    }
   ],
   "source": [
    "trainingDict = {}\n",
    "trainingDict['global4'] = (dataLen, saveModel(NewGlobal, '4'))\n",
    "globalDict['global4'] = trainingDict['global4']\n",
    "trainingDict['J'] = local_train('J','./data/dataG.csv', 4)\n",
    "trainingDict['K'] = local_train('K','./data/dataH.csv', 4)\n",
    "NewGlobal, dataLen = FedAvg(trainingDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints in Testing dataset:  75\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x13ad07160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.9067\n",
      "Loss:  0.6928359270095825\n",
      "Accuracy:  0.9066666960716248\n"
     ]
    }
   ],
   "source": [
    "trainingDict = {}\n",
    "trainingDict['global5'] = (dataLen, saveModel(NewGlobal, '5'))\n",
    "globalDict['global5'] = trainingDict['global5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global1': (20, 0.746666669845581),\n",
       " 'global2': (159.0, 0.7866666913032532),\n",
       " 'global3': (264.0, 0.5333333611488342),\n",
       " 'global4': (408.0, 0.8799999952316284),\n",
       " 'global5': (505.0, 0.9066666960716248)}"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globalDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
