{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import plotly.express as px\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genesis_train(file):\n",
    "    data = pd.read_csv(file)\n",
    "    del data['Unnamed: 32']\n",
    "    print('Number of datapoints in Training dataset: ',len(data))\n",
    "    X_train = data.iloc[:, 2:].values\n",
    "    y_train = data.iloc[:, 1].values\n",
    "    \n",
    "    test = pd.read_csv('./data/test.csv')\n",
    "    del test['Unnamed: 32']\n",
    "    print('Number of datapoints in Testing dataset: ',len(test))\n",
    "    X_test = test.iloc[:, 2:].values\n",
    "    y_test = test.iloc[:, 1].values\n",
    "\n",
    "    labelencoder = LabelEncoder()\n",
    "    y_train = labelencoder.fit_transform(y_train)\n",
    "    y_test = labelencoder.fit_transform(y_test)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(16, activation='relu', input_dim=30))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=100, epochs=5)\n",
    "\n",
    "    scores = model.evaluate(X_test, y_test)\n",
    "    print(\"Loss: \", scores[0])        #Loss\n",
    "    print(\"Accuracy: \", scores[1])    #Accuracy\n",
    "\n",
    "    #Saving Model\n",
    "    model.save(\"./weights/global1.h5\")\n",
    "    return len(data), scores[0], scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_train(name,file, globalId):\n",
    "    data = pd.read_csv(file)\n",
    "    del data['Unnamed: 32']\n",
    "    print('Number of datapoints in Testing dataset: ',len(data))\n",
    "    X_train = data.iloc[:, 2:].values\n",
    "    y_train = data.iloc[:, 1].values\n",
    "    \n",
    "    test = pd.read_csv('./data/test.csv')\n",
    "    del test['Unnamed: 32']\n",
    "    print('Number of datapoints in Testing dataset: ',len(test))\n",
    "    X_test = test.iloc[:, 2:].values\n",
    "    y_test = test.iloc[:, 1].values\n",
    "\n",
    "    labelencoder = LabelEncoder()\n",
    "    y_train = labelencoder.fit_transform(y_train)\n",
    "    y_test = labelencoder.fit_transform(y_test)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(16, activation='relu', input_dim=30))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.load_weights(\"./weights/global\"+str(globalId)+\".h5\")\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=100, epochs=5)\n",
    "\n",
    "    scores = model.evaluate(X_test, y_test)\n",
    "    print(\"Loss: \", scores[0])        #Loss\n",
    "    print(\"Accuracy: \", scores[1])    #Accuracy\n",
    "\n",
    "    #Saving Model\n",
    "    model.save(\"./weights/\" + str(name) + \".h5\")\n",
    "    return len(data), scores[0], float(scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataLen(trainingDf):\n",
    "    n = 0\n",
    "    for w in trainingDf.iloc():\n",
    "        n += w.DataSize\n",
    "    print('Total number of data points after this round: ', n)\n",
    "    return n\n",
    "\n",
    "def assignWeights(trainingDf):\n",
    "    n = getDataLen(trainingDf)\n",
    "    trainingDf['Weightage'] = trainingDf['DataSize'].apply(lambda x: x/n)\n",
    "    return trainingDf, n\n",
    "    \n",
    "def scale(weight, scaler):\n",
    "    scaledWeights = []\n",
    "    for i in range(len(weight)):\n",
    "        scaledWeights.append(scaler * weight[i])\n",
    "    return scaledWeights\n",
    "\n",
    "def getScaledWeight(m, scaler):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, activation='relu', input_dim=30))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    fpath = \"./weights/\"+m+\".h5\"\n",
    "    model.load_weights(fpath)\n",
    "    weight = model.get_weights()\n",
    "    return scale(weight, scaler)\n",
    "\n",
    "def avgWeights(scaledWeights):\n",
    "    avg = list()\n",
    "    for weight_list_tuple in zip(*scaledWeights):\n",
    "        layer_mean = tf.math.reduce_sum(weight_list_tuple, axis=0)\n",
    "        avg.append(layer_mean)\n",
    "    return avg\n",
    "\n",
    "def getWeights(m):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, activation='relu', input_dim=30))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    fpath = \"./weights/\"+m+\".h5\"\n",
    "    model.load_weights(fpath)\n",
    "    weight = model.get_weights()\n",
    "    return weight\n",
    "\n",
    "def avgWeights(weights):\n",
    "    avg = list()\n",
    "    for weight_list_tuple in zip(*weights):\n",
    "        layer_mean = tf.math.reduce_sum(weight_list_tuple, axis=0)\n",
    "        avg.append(layer_mean)\n",
    "    return avg\n",
    "\n",
    "def FedAvg(trainingDict):\n",
    "    trainingDf = pd.DataFrame.from_dict(trainingDict, orient='index', columns=['DataSize','Loss', 'Accuracy']) \n",
    "    models = []\n",
    "    for i in trainingDict.keys():\n",
    "        if 'global' not in i:\n",
    "            models.append(i)\n",
    "    scaledWeights = []\n",
    "    trainingDf, dataLen = assignWeights(trainingDf)\n",
    "    for m in models:\n",
    "        scaledWeights.append(getScaledWeight(m, trainingDf.loc[m]['Weightage']))\n",
    "    fedAvgWeight = avgWeights(scaledWeights)\n",
    "    return fedAvgWeight, dataLen\n",
    "\n",
    "def ZenoScore(local, g_loss, p):\n",
    "    scored = {}\n",
    "    for l in local.keys():\n",
    "        score = g_loss - local[l][1] - (local[l][0]*p)\n",
    "        scored[l] = score\n",
    "    return scored\n",
    "        \n",
    "\n",
    "def zeno(trainingDict, p, b):\n",
    "    \n",
    "    models = list(trainingDict.keys())\n",
    "    \n",
    "    trainingDf = pd.DataFrame.from_dict(trainingDict, orient='index', columns=['DataSize', 'Loss', 'Accuracy']) \n",
    "    \n",
    "    g_loss = 0    \n",
    "    local = {}\n",
    "    \n",
    "    for i in trainingDict.keys():\n",
    "        if 'global' in i:\n",
    "            g_loss = trainingDict[i][1]\n",
    "        else:\n",
    "            local[i] = (trainingDict[i])\n",
    "            \n",
    "    \n",
    "    scores = ZenoScore(local, g_loss, p)\n",
    "    b = int(len(scores)*b)\n",
    "    sortedScores = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1])}\n",
    "    \n",
    "    zenoedModels = []\n",
    "    \n",
    "    for i in range(b):\n",
    "        zenoedModels.append((sortedScores.popitem())[0])\n",
    "        \n",
    "    newDict = {}\n",
    "    for i in trainingDict.keys():\n",
    "        if i not in zenoedModels:\n",
    "            newDict[i] = trainingDict[i]\n",
    "            \n",
    "    print('Zeno Selections: ', zenoedModels)\n",
    "        \n",
    "    NewGlobal, dataLen = FedAvg(trainingDict)\n",
    "    \n",
    "    return NewGlobal, dataLen\n",
    "\n",
    "def saveModel(weights, n):\n",
    "    \n",
    "    test = pd.read_csv('./data/test.csv')\n",
    "    del test['Unnamed: 32']\n",
    "    print('Number of datapoints in Testing dataset: ',len(test))\n",
    "    X_test = test.iloc[:, 2:].values\n",
    "    y_test = test.iloc[:, 1].values\n",
    "\n",
    "    labelencoder = LabelEncoder()\n",
    "    y_test = labelencoder.fit_transform(y_test)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(16, activation='relu', input_dim=30))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.set_weights(weights)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    scores = model.evaluate(X_test, y_test)\n",
    "    print(\"Loss: \", scores[0])        #Loss\n",
    "    print(\"Accuracy: \", scores[1])    #Accuracy\n",
    "\n",
    "    #Saving Model\n",
    "    fpath = \"./weights/global\"+n+\".h5\"\n",
    "    model.save(fpath)\n",
    "    return (scores[0], scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints in Training dataset:  20\n",
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 69.9075 - accuracy: 0.4500\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 81.4224 - accuracy: 0.4500\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 78.1365 - accuracy: 0.4000\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 66.9329 - accuracy: 0.4000\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 62.7361 - accuracy: 0.5000\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x13dd5ac10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 66.0796 - accuracy: 0.2533\n",
      "Loss:  66.0795669555664\n",
      "Accuracy:  0.25333333015441895\n",
      "Number of datapoints in Testing dataset:  49\n",
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 35.8560 - accuracy: 0.5714\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 45.4825 - accuracy: 0.4694\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 53.5399 - accuracy: 0.4898\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 27.5609 - accuracy: 0.6327\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 37.6698 - accuracy: 0.6122\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x1406a9790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 48.3929 - accuracy: 0.2533\n",
      "Loss:  48.39285659790039\n",
      "Accuracy:  0.25333333015441895\n",
      "Number of datapoints in Testing dataset:  46\n",
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 68.1364 - accuracy: 0.3913\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 59.3749 - accuracy: 0.4130\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 61.8578 - accuracy: 0.3913\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 57.0023 - accuracy: 0.4130\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 59.6878 - accuracy: 0.3478\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x1406a9550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 47.5818 - accuracy: 0.2533\n",
      "Loss:  47.581783294677734\n",
      "Accuracy:  0.25333333015441895\n",
      "Number of datapoints in Testing dataset:  44\n",
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 46.6177 - accuracy: 0.3636\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 45.2813 - accuracy: 0.4091\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 47.8543 - accuracy: 0.4318\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 52.5094 - accuracy: 0.3409\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 37.6979 - accuracy: 0.4318\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x13ead9940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 47.8286 - accuracy: 0.2533\n",
      "Loss:  47.828617095947266\n",
      "Accuracy:  0.25333333015441895\n",
      "Number of datapoints in Testing dataset:  41\n",
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 35.0770 - accuracy: 0.6585\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 47.9376 - accuracy: 0.5366\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 32.9047 - accuracy: 0.6585\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 37.9103 - accuracy: 0.6098\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 36.5156 - accuracy: 0.5366\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x1419115e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 47.5994 - accuracy: 0.2533\n",
      "Loss:  47.59942626953125\n",
      "Accuracy:  0.25333333015441895\n",
      "Number of datapoints in Testing dataset:  18\n",
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 55.5353 - accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 61.3703 - accuracy: 0.3333\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 63.0487 - accuracy: 0.3333\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 55.2004 - accuracy: 0.3333\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 47.5612 - accuracy: 0.4444\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x141911af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 47.8981 - accuracy: 0.2533\n",
      "Loss:  47.89811706542969\n",
      "Accuracy:  0.25333333015441895\n"
     ]
    }
   ],
   "source": [
    "#### Zeno ####\n",
    "globalDict = dict()\n",
    "trainingDict = dict()\n",
    "trainingDict['global1'] = genesis_train('./data/genesis.csv')\n",
    "globalDict['global1'] = trainingDict['global1']\n",
    "trainingDict['A'] = local_train('A','./data/dataA.csv', 1)\n",
    "trainingDict['B'] = local_train('B','./data/dataB.csv', 1)\n",
    "trainingDict['C'] = local_train('C','./data/dataC.csv', 1)\n",
    "trainingDict['D'] = local_train('B','./data/dataD.csv', 1)\n",
    "trainingDict['E'] = local_train('C','./data/dataE.csv', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global1': (20, 66.0795669555664, 0.25333333015441895),\n",
       " 'A': (49, 48.39285659790039, 0.25333333015441895),\n",
       " 'B': (46, 47.581783294677734, 0.25333333015441895),\n",
       " 'C': (44, 47.828617095947266, 0.25333333015441895),\n",
       " 'D': (41, 47.59942626953125, 0.25333333015441895),\n",
       " 'E': (18, 47.89811706542969, 0.25333333015441895)}"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeno Selections:  ['B', 'D', 'C']\n",
      "Total number of data points after this round:  218.0\n"
     ]
    }
   ],
   "source": [
    "NewGlobal, dataLen = zeno(trainingDict, 0.0005, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints in Testing dataset:  75\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x1414a5280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 8.9285 - accuracy: 0.7467\n",
      "Loss:  8.928487777709961\n",
      "Accuracy:  0.746666669845581\n",
      "Number of datapoints in Testing dataset:  46\n",
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.7789 - accuracy: 0.6957\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.4739 - accuracy: 0.6957\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.0971 - accuracy: 0.7609\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.1207 - accuracy: 0.7391\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.9336 - accuracy: 0.5652\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x141b58e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5841 - accuracy: 0.9067\n",
      "Loss:  0.584122896194458\n",
      "Accuracy:  0.9066666960716248\n",
      "Number of datapoints in Testing dataset:  52\n",
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.7191 - accuracy: 0.5577\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 15.6581 - accuracy: 0.6154\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.5463 - accuracy: 0.6154\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.4743 - accuracy: 0.6923\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.2666 - accuracy: 0.7115\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x141cc91f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5825 - accuracy: 0.9067\n",
      "Loss:  0.5824934840202332\n",
      "Accuracy:  0.9066666960716248\n",
      "Number of datapoints in Testing dataset:  45\n",
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.4134 - accuracy: 0.8000\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.3073 - accuracy: 0.7778\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4307 - accuracy: 0.8444\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.2166 - accuracy: 0.7556\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.1716 - accuracy: 0.7333\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x141cc9700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6103 - accuracy: 0.9067\n",
      "Loss:  0.6103257536888123\n",
      "Accuracy:  0.9066666960716248\n",
      "Number of datapoints in Testing dataset:  47\n",
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.0403 - accuracy: 0.6809\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.3354 - accuracy: 0.7447\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.8123 - accuracy: 0.7234\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.0004 - accuracy: 0.6809\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7315 - accuracy: 0.7234\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x13dbe4ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5847 - accuracy: 0.9067\n",
      "Loss:  0.5847291946411133\n",
      "Accuracy:  0.9066666960716248\n",
      "Number of datapoints in Testing dataset:  42\n",
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.2311 - accuracy: 0.6667\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.2774 - accuracy: 0.6905\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.8879 - accuracy: 0.7381\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.4116 - accuracy: 0.6429\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.6501 - accuracy: 0.7143\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x13efcf820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4652 - accuracy: 0.9375WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_test_batch_end` time: 0.0041s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6300 - accuracy: 0.9200\n",
      "Loss:  0.6300356388092041\n",
      "Accuracy:  0.9200000166893005\n"
     ]
    }
   ],
   "source": [
    "trainingDict = {}\n",
    "newModelLoss, newModelAccuracy = saveModel(NewGlobal, '2')\n",
    "trainingDict['global2'] = (dataLen, newModelLoss, newModelAccuracy)\n",
    "globalDict['global2'] = trainingDict['global2']\n",
    "trainingDict['F'] = local_train('F','./data/dataF.csv', 2)\n",
    "trainingDict['G'] = local_train('G','./data/dataG.csv', 2)\n",
    "trainingDict['H'] = local_train('H','./data/dataH.csv', 2)\n",
    "trainingDict['I'] = local_train('I','./data/dataI.csv', 2)\n",
    "trainingDict['J'] = local_train('K','./data/dataJ.csv', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeno Selections:  ['F', 'I', 'G']\n",
      "Total number of data points after this round:  450.0\n"
     ]
    }
   ],
   "source": [
    "NewGlobal, dataLen = zeno(trainingDict, 0.0005, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints in Testing dataset:  75\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x13e039310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.8267\n",
      "Loss:  0.4605107009410858\n",
      "Accuracy:  0.8266666531562805\n"
     ]
    }
   ],
   "source": [
    "trainingDict = {}\n",
    "newModelLoss, newModelAccuracy = saveModel(NewGlobal, '3')\n",
    "trainingDict['global3'] = (dataLen, newModelLoss, newModelAccuracy)\n",
    "globalDict['global3'] = trainingDict['global3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
