{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, GaussianNoise\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sys\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genesis_train(file):\n",
    "    data = pd.read_csv(file)\n",
    "    if 'Unnamed: 32' in data.columns:\n",
    "        del data['Unnamed: 32']\n",
    "    print('Number of datapoints in Training dataset: ',len(data))\n",
    "    X_train = data.iloc[:, 2:].values\n",
    "    y_train = data.iloc[:, 1].values\n",
    "    \n",
    "    test = pd.read_csv('./data/test.csv')\n",
    "    del test['Unnamed: 32']\n",
    "    print('Number of datapoints in Testing dataset: ',len(test))\n",
    "    X_test = test.iloc[:, 2:].values\n",
    "    y_test = test.iloc[:, 1].values\n",
    "\n",
    "    labelencoder = LabelEncoder()\n",
    "    y_train = labelencoder.fit_transform(y_train)\n",
    "    y_test = labelencoder.fit_transform(y_test)\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(16, activation='relu', input_dim=30))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=100, epochs=10)\n",
    "\n",
    "    scores = model.evaluate(X_test, y_test)\n",
    "    print(\"Loss: \", scores[0])        #Loss\n",
    "    print(\"Accuracy: \", scores[1])    #Accuracy\n",
    "\n",
    "    #Saving Model\n",
    "    model.save(\"./output.h5\")\n",
    "    return scores[1]\n",
    "\n",
    "def genesis_train_gaussian_noise(file):\n",
    "    data = pd.read_csv(file)\n",
    "    if 'Unnamed: 32' in data.columns:\n",
    "        del data['Unnamed: 32']\n",
    "    print('Number of datapoints in Training dataset: ',len(data))\n",
    "    X_train = data.iloc[:, 2:].values\n",
    "    y_train = data.iloc[:, 1].values\n",
    "    \n",
    "    data = GaussianNoise(0.2)(data)\n",
    "    \n",
    "    test = pd.read_csv('./data/test.csv')\n",
    "    del test['Unnamed: 32']\n",
    "    print('Number of datapoints in Testing dataset: ',len(test))\n",
    "    X_test = test.iloc[:, 2:].values\n",
    "    y_test = test.iloc[:, 1].values\n",
    "\n",
    "    labelencoder = LabelEncoder()\n",
    "    y_train = labelencoder.fit_transform(y_train)\n",
    "    y_test = labelencoder.fit_transform(y_test)\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(16, activation='relu', input_dim=30))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=100, epochs=10)\n",
    "\n",
    "    scores = model.evaluate(X_test, y_test)\n",
    "    print(\"Loss: \", scores[0])        #Loss\n",
    "    print(\"Accuracy: \", scores[1])    #Accuracy\n",
    "\n",
    "    #Saving Model\n",
    "    model.save(\"./output.h5\")\n",
    "    return scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints in Training dataset:  494\n",
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7030 - accuracy: 0.5040\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6390 - accuracy: 0.5992\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5882 - accuracy: 0.7004\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5344 - accuracy: 0.7814\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5030 - accuracy: 0.8421\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.8745\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.9049\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3851 - accuracy: 0.9130\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3438 - accuracy: 0.9170\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3181 - accuracy: 0.9372\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x13a582c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 783us/step - loss: 0.3359 - accuracy: 0.9200\n",
      "Loss:  0.3359147608280182\n",
      "Accuracy:  0.9200000166893005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9200000166893005"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genesis_train('./data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints in Training dataset:  494\n",
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6456 - accuracy: 0.6397\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5847 - accuracy: 0.7126\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5130 - accuracy: 0.8057\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.8360\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4198 - accuracy: 0.8745\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3913 - accuracy: 0.8725\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3351 - accuracy: 0.9089\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3387 - accuracy: 0.8988\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3151 - accuracy: 0.8968\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2956 - accuracy: 0.9130\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x13966d670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 749us/step - loss: 0.2283 - accuracy: 0.9467\n",
      "Loss:  0.22832387685775757\n",
      "Accuracy:  0.9466666579246521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9466666579246521"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genesis_train_gaussian_noise('./data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
