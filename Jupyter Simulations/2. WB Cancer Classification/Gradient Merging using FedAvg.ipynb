{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sys\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genesis_train(file):\n",
    "    data = pd.read_csv(file)\n",
    "    del data['Unnamed: 32']\n",
    "    print('Number of datapoints in Training dataset: ',len(data))\n",
    "    X_train = data.iloc[:, 2:].values\n",
    "    y_train = data.iloc[:, 1].values\n",
    "    \n",
    "    test = pd.read_csv('./data/test.csv')\n",
    "    del test['Unnamed: 32']\n",
    "    print('Number of datapoints in Testing dataset: ',len(test))\n",
    "    X_test = test.iloc[:, 2:].values\n",
    "    y_test = test.iloc[:, 1].values\n",
    "\n",
    "    labelencoder = LabelEncoder()\n",
    "    y_train = labelencoder.fit_transform(y_train)\n",
    "    y_test = labelencoder.fit_transform(y_test)\n",
    "\n",
    "#     sc = StandardScaler()\n",
    "#     X_train = sc.fit_transform(X_train)\n",
    "#     X_test = sc.transform(X_test)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(16, activation='relu', input_dim=30))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=100, epochs=5)\n",
    "\n",
    "    scores = model.evaluate(X_test, y_test)\n",
    "    print(\"Loss: \", scores[0])        #Loss\n",
    "    print(\"Accuracy: \", scores[1])    #Accuracy\n",
    "\n",
    "    #Saving Model\n",
    "    model.save(\"./weights/output.h5\")\n",
    "    return len(data), scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_train(name,file):\n",
    "    data = pd.read_csv(file)\n",
    "    del data['Unnamed: 32']\n",
    "    X_train = data.iloc[:, 2:].values\n",
    "    y_train = data.iloc[:, 1].values\n",
    "    \n",
    "    test = pd.read_csv('./data/test.csv')\n",
    "    del test['Unnamed: 32']\n",
    "    print('Number of datapoints in Testing dataset: ',len(test))\n",
    "    X_test = test.iloc[:, 2:].values\n",
    "    y_test = test.iloc[:, 1].values\n",
    "\n",
    "    labelencoder = LabelEncoder()\n",
    "    y_train = labelencoder.fit_transform(y_train)\n",
    "    y_test = labelencoder.fit_transform(y_test)\n",
    "\n",
    "#     sc = StandardScaler()\n",
    "#     X_train = sc.fit_transform(X_train)\n",
    "#     X_test = sc.transform(X_test)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(16, activation='relu', input_dim=30))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.load_weights(\"./weights/output.h5\")\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=100, epochs=5)\n",
    "\n",
    "    scores = model.evaluate(X_test, y_test)\n",
    "    print(\"Loss: \", scores[0])        #Loss\n",
    "    print(\"Accuracy: \", scores[1])    #Accuracy\n",
    "\n",
    "    #Saving Model\n",
    "    model.save(\"./weights/\" + str(name) + \".h5\")\n",
    "    return len(data), float(scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints in Training dataset:  20\n",
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 37.8720 - accuracy: 0.5500\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 45.9235 - accuracy: 0.5500\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 822us/step - loss: 37.1114 - accuracy: 0.5500\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 28.1026 - accuracy: 0.6500\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 31.5304 - accuracy: 0.5500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 18.7440 - accuracy: 0.7467\n",
      "Loss:  18.744049072265625\n",
      "Accuracy:  0.746666669845581\n",
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 34.3565 - accuracy: 0.4286\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 856us/step - loss: 32.0545 - accuracy: 0.4490\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 33.7427 - accuracy: 0.4898\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 30.4849 - accuracy: 0.4898\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 22.7271 - accuracy: 0.4898\n",
      "3/3 [==============================] - 0s 847us/step - loss: 12.3680 - accuracy: 0.7467\n",
      "Loss:  12.368022918701172\n",
      "Accuracy:  0.746666669845581\n",
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 27.2838 - accuracy: 0.6522\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 848us/step - loss: 27.5899 - accuracy: 0.5652\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.4990 - accuracy: 0.5652\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 28.8557 - accuracy: 0.6087\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 19.4409 - accuracy: 0.6522\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 12.4561 - accuracy: 0.7467\n",
      "Loss:  12.4560546875\n",
      "Accuracy:  0.746666669845581\n",
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 24.9273 - accuracy: 0.5909\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 845us/step - loss: 26.8065 - accuracy: 0.6136\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 20.6108 - accuracy: 0.6591\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 23.5170 - accuracy: 0.5909\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 22.6140 - accuracy: 0.5682\n",
      "3/3 [==============================] - 0s 940us/step - loss: 12.3830 - accuracy: 0.7467\n",
      "Loss:  12.383003234863281\n",
      "Accuracy:  0.746666669845581\n",
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 972us/step - loss: 35.5382 - accuracy: 0.4390\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 27.3809 - accuracy: 0.3902\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 28.9988 - accuracy: 0.3659\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 26.3622 - accuracy: 0.4146\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 25.0685 - accuracy: 0.4146\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x137261550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 820us/step - loss: 12.3576 - accuracy: 0.7467\n",
      "Loss:  12.357634544372559\n",
      "Accuracy:  0.746666669845581\n",
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 20.2980 - accuracy: 0.6667\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 842us/step - loss: 20.0328 - accuracy: 0.7222\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 21.2757 - accuracy: 0.6667\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.4940 - accuracy: 0.6111\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 20.3792 - accuracy: 0.6667\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x137bddca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 981us/step - loss: 12.7344 - accuracy: 0.7467\n",
      "Loss:  12.734356880187988\n",
      "Accuracy:  0.746666669845581\n",
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 21.9249 - accuracy: 0.6087\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 836us/step - loss: 16.8140 - accuracy: 0.5870\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 15.2637 - accuracy: 0.6522\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.9629 - accuracy: 0.7174\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.6849 - accuracy: 0.7174\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x1373a0d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 12.4387 - accuracy: 0.7467\n",
      "Loss:  12.438663482666016\n",
      "Accuracy:  0.746666669845581\n",
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 40.6541 - accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 848us/step - loss: 37.3081 - accuracy: 0.4615\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 38.3230 - accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 850us/step - loss: 30.5922 - accuracy: 0.4808\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 30.6485 - accuracy: 0.4615\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x137ad7ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 793us/step - loss: 12.3414 - accuracy: 0.7467\n",
      "Loss:  12.341400146484375\n",
      "Accuracy:  0.746666669845581\n",
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.0890 - accuracy: 0.7778\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 975us/step - loss: 12.1122 - accuracy: 0.7556\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.6406 - accuracy: 0.8444\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.3665 - accuracy: 0.6889\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.9759 - accuracy: 0.6889\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x137f9cb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 12.5387 - accuracy: 0.7467\n",
      "Loss:  12.538736343383789\n",
      "Accuracy:  0.746666669845581\n",
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 24.3589 - accuracy: 0.5745\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 928us/step - loss: 14.7606 - accuracy: 0.7447\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 887us/step - loss: 23.4590 - accuracy: 0.6809\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5944 - accuracy: 0.5532\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 15.2988 - accuracy: 0.5319\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x1381d3430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 930us/step - loss: 12.5569 - accuracy: 0.7467\n",
      "Loss:  12.556865692138672\n",
      "Accuracy:  0.746666669845581\n",
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 25.3748 - accuracy: 0.5952\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 868us/step - loss: 24.3510 - accuracy: 0.6429\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 21.5607 - accuracy: 0.6190\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.1104 - accuracy: 0.7143\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 20.2888 - accuracy: 0.6190\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x138250ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 12.4352 - accuracy: 0.7467\n",
      "Loss:  12.435154914855957\n",
      "Accuracy:  0.746666669845581\n",
      "Number of datapoints in Testing dataset:  75\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.6698 - accuracy: 0.6364\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 908us/step - loss: 21.9611 - accuracy: 0.6591\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 959us/step - loss: 13.6522 - accuracy: 0.7045\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 831us/step - loss: 20.4600 - accuracy: 0.6818\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 17.7509 - accuracy: 0.6591\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x1383c08b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 798us/step - loss: 12.6602 - accuracy: 0.7467\n",
      "Loss:  12.660170555114746\n",
      "Accuracy:  0.746666669845581\n"
     ]
    }
   ],
   "source": [
    "FLAccuracy = dict()\n",
    "FLAccuracy['Genesis'] = genesis_train('./data/genesis.csv')\n",
    "FLAccuracy['A'] = update_train('A','./data/dataA.csv')\n",
    "FLAccuracy['B'] = update_train('B','./data/dataB.csv')\n",
    "FLAccuracy['C'] = update_train('C','./data/dataC.csv')\n",
    "FLAccuracy['D'] = update_train('D','./data/dataD.csv')\n",
    "FLAccuracy['E'] = update_train('E','./data/dataE.csv')\n",
    "FLAccuracy['F'] = update_train('F','./data/dataF.csv')\n",
    "FLAccuracy['G'] = update_train('G','./data/dataG.csv')\n",
    "FLAccuracy['H'] = update_train('H','./data/dataH.csv')\n",
    "FLAccuracy['I'] = update_train('I','./data/dataI.csv')\n",
    "FLAccuracy['J'] = update_train('J','./data/dataJ.csv')\n",
    "FLAccuracy['K'] = update_train('K','./data/dataK.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Genesis': (20, 0.746666669845581),\n",
       " 'A': (49, 0.746666669845581),\n",
       " 'B': (46, 0.746666669845581),\n",
       " 'C': (44, 0.746666669845581),\n",
       " 'D': (41, 0.746666669845581),\n",
       " 'E': (18, 0.746666669845581),\n",
       " 'F': (46, 0.746666669845581),\n",
       " 'G': (52, 0.746666669845581),\n",
       " 'H': (45, 0.746666669845581),\n",
       " 'I': (47, 0.746666669845581),\n",
       " 'J': (42, 0.746666669845581),\n",
       " 'K': (44, 0.746666669845581)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FLAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataSize</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Genesis</th>\n",
       "      <td>20</td>\n",
       "      <td>0.746667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>49</td>\n",
       "      <td>0.746667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>46</td>\n",
       "      <td>0.746667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>44</td>\n",
       "      <td>0.746667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>41</td>\n",
       "      <td>0.746667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>18</td>\n",
       "      <td>0.746667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>46</td>\n",
       "      <td>0.746667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>52</td>\n",
       "      <td>0.746667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H</th>\n",
       "      <td>45</td>\n",
       "      <td>0.746667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>47</td>\n",
       "      <td>0.746667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J</th>\n",
       "      <td>42</td>\n",
       "      <td>0.746667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K</th>\n",
       "      <td>44</td>\n",
       "      <td>0.746667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DataSize  Accuracy\n",
       "Genesis        20  0.746667\n",
       "A              49  0.746667\n",
       "B              46  0.746667\n",
       "C              44  0.746667\n",
       "D              41  0.746667\n",
       "E              18  0.746667\n",
       "F              46  0.746667\n",
       "G              52  0.746667\n",
       "H              45  0.746667\n",
       "I              47  0.746667\n",
       "J              42  0.746667\n",
       "K              44  0.746667"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FLAccuracyDF = pd.DataFrame.from_dict(FLAccuracy, orient='index', columns=['DataSize', 'Accuracy'])\n",
    "FLAccuracyDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Genesis', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FLAccuracyDF.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "ix is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7071651fc054>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mFLAccuracyDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataSize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Total number of data points in this round: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ix is not iterable\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: ix is not iterable"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for w in FLAccuracyDF.iloc():\n",
    "    n += w.DataSize\n",
    "print('Total number of data points in this round: ', n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAccuracyDF['Weightage'] = FLAccuracyDF['DataSize'].apply(lambda x: x/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataSize</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Weightage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Genesis</th>\n",
       "      <td>20</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.040486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>49</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.099190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>46</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.093117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>44</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.089069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>41</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.082996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>18</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.036437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>46</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.093117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>52</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H</th>\n",
       "      <td>45</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.091093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>47</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.095142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J</th>\n",
       "      <td>42</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.085020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K</th>\n",
       "      <td>44</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.089069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DataSize  Accuracy  Weightage\n",
       "Genesis        20  0.240000   0.040486\n",
       "A              49  0.253333   0.099190\n",
       "B              46  0.253333   0.093117\n",
       "C              44  0.293333   0.089069\n",
       "D              41  0.253333   0.082996\n",
       "E              18  0.253333   0.036437\n",
       "F              46  0.320000   0.093117\n",
       "G              52  0.253333   0.105263\n",
       "H              45  0.733333   0.091093\n",
       "I              47  0.293333   0.095142\n",
       "J              42  0.253333   0.085020\n",
       "K              44  0.253333   0.089069"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FLAccuracyDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(weight, scaler):\n",
    "    scaledWeights = []\n",
    "    for i in range(len(weight)):\n",
    "        scaledWeights.append(scaler * weight[i])\n",
    "    return scaledWeights\n",
    "\n",
    "def getScaledWeight(m, scaler):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, activation='relu', input_dim=30))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    fpath = \"./weights/\"+m+\".h5\"\n",
    "    model.load_weights(fpath)\n",
    "    weight = model.get_weights()\n",
    "    scaledWeight = scale(weight, scaler)\n",
    "\n",
    "    return scaledWeight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgWeights(scaledWeights):\n",
    "    avg = list()\n",
    "    for weight_list_tuple in zip(*scaledWeights):\n",
    "        layer_mean = tf.math.reduce_sum(weight_list_tuple, axis=0)\n",
    "        avg.append(layer_mean)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FedAvg(models):\n",
    "    \n",
    "    scaledWeights = []\n",
    "    for m in models:\n",
    "        scaledWeights.append(getScaledWeight(m, FLAccuracyDF.loc[m]['Weightage']))\n",
    "    \n",
    "    avgWeight = avgWeights(scaledWeights)\n",
    "    return avgWeight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(30, 16), dtype=float32, numpy=\n",
      "array([[ 0.2057464 , -0.2657927 , -0.25285888, -0.24868095, -0.27177823,\n",
      "         0.32082295,  0.17813817, -0.2762046 ,  0.15874425, -0.19060329,\n",
      "         0.04024782,  0.2358241 , -0.06689931, -0.18333879,  0.2137917 ,\n",
      "         0.27995768],\n",
      "       [-0.26607943, -0.15886399,  0.00093831, -0.28260505, -0.00071617,\n",
      "         0.0422643 ,  0.18987222,  0.19548495,  0.06701235, -0.07441676,\n",
      "        -0.303952  ,  0.01502862, -0.21088326, -0.22428352, -0.23013252,\n",
      "        -0.25867918],\n",
      "       [-0.08973237,  0.24541888,  0.00931878,  0.18099858,  0.20778519,\n",
      "         0.04198923,  0.21883336,  0.33724394,  0.0916836 , -0.10704709,\n",
      "        -0.15457837,  0.29787248, -0.25978634,  0.1385961 , -0.08112531,\n",
      "        -0.09184094],\n",
      "       [ 0.17914766,  0.05103307,  0.12961589,  0.00284287,  0.19499469,\n",
      "        -0.19313732,  0.09373255,  0.17487596,  0.07619544, -0.15862216,\n",
      "        -0.31945598, -0.10518299, -0.09112987,  0.1427899 , -0.15514548,\n",
      "         0.05773725],\n",
      "       [ 0.04782367,  0.09918013, -0.33992952, -0.27662063,  0.17564726,\n",
      "        -0.32703695, -0.07112692, -0.27329865,  0.18911932, -0.08566506,\n",
      "        -0.1899365 ,  0.12468123, -0.16841768, -0.33264673,  0.15739109,\n",
      "         0.10830704],\n",
      "       [ 0.338996  ,  0.23406683, -0.06385297, -0.22219579,  0.15422963,\n",
      "         0.19008502, -0.12906036, -0.01336864, -0.08010406,  0.13618827,\n",
      "        -0.23629901, -0.07175781,  0.31328064,  0.28254828, -0.32322282,\n",
      "         0.01917789],\n",
      "       [ 0.15064731, -0.3100951 ,  0.30420035,  0.09927227, -0.27242863,\n",
      "        -0.20053932,  0.23865497, -0.04773141,  0.32906023, -0.256203  ,\n",
      "        -0.21363558, -0.01716605,  0.21282363,  0.21361534, -0.28623286,\n",
      "         0.15752533],\n",
      "       [-0.20723043, -0.24021924, -0.08635791, -0.15883376, -0.24809928,\n",
      "         0.18638195,  0.29719344,  0.1888334 , -0.2672725 ,  0.18062693,\n",
      "         0.16025257, -0.20299894,  0.31281647, -0.21172352,  0.1090446 ,\n",
      "        -0.07481122],\n",
      "       [-0.2310481 , -0.17771545,  0.03313778, -0.17341879,  0.211276  ,\n",
      "        -0.01630195, -0.25168446, -0.04028303,  0.0318008 ,  0.11276674,\n",
      "         0.3440811 ,  0.02757714,  0.04640244, -0.03107752, -0.13391598,\n",
      "         0.19369152],\n",
      "       [-0.0196679 , -0.26524675, -0.3412787 ,  0.2737565 , -0.26589036,\n",
      "         0.21901694, -0.27806434, -0.19171503,  0.2056436 ,  0.27801624,\n",
      "        -0.25446728, -0.19178456,  0.17045134, -0.31625378, -0.26673284,\n",
      "        -0.09247784],\n",
      "       [ 0.08036719,  0.24299866, -0.33575127,  0.16865502, -0.04915495,\n",
      "        -0.3176623 , -0.15963522, -0.29561597,  0.23779082, -0.31015095,\n",
      "         0.17702277,  0.13415915,  0.11148001,  0.05648534,  0.01514385,\n",
      "         0.08427032],\n",
      "       [ 0.10188951,  0.11927055, -0.3101983 , -0.21012945,  0.0541821 ,\n",
      "         0.20553754,  0.24776092,  0.02506226, -0.13945745,  0.30984014,\n",
      "         0.25201207, -0.11144291, -0.30522877,  0.33331344,  0.16584073,\n",
      "         0.00138946],\n",
      "       [-0.07113599, -0.21918173, -0.31386116,  0.27858824, -0.09744248,\n",
      "         0.20283622, -0.02844905, -0.17638873, -0.08468045,  0.1174515 ,\n",
      "         0.15705834, -0.21520385, -0.19362202, -0.18959749, -0.18221349,\n",
      "         0.08331637],\n",
      "       [ 0.04386102,  0.24393973, -0.31002903,  0.07762501,  0.03123632,\n",
      "        -0.11121941, -0.18369444, -0.13252844,  0.18619156, -0.15604143,\n",
      "         0.2562999 ,  0.1400212 ,  0.14870638,  0.03208544, -0.01359531,\n",
      "        -0.34710473],\n",
      "       [ 0.2234877 , -0.03595201, -0.29676393,  0.23497677,  0.34470636,\n",
      "        -0.26391762,  0.09820479,  0.15513194, -0.01015001, -0.09133623,\n",
      "         0.02697305,  0.19979165, -0.34739125,  0.16734147, -0.29083288,\n",
      "         0.04711802],\n",
      "       [-0.2552171 ,  0.1313862 ,  0.16468033,  0.14961232,  0.10560234,\n",
      "         0.11962771,  0.08110943, -0.23707117,  0.14794505, -0.15941185,\n",
      "        -0.18979551,  0.08797219, -0.13025379, -0.13308515, -0.1358259 ,\n",
      "         0.13362153],\n",
      "       [ 0.08265181,  0.05824617, -0.1528792 , -0.06458656, -0.22926725,\n",
      "         0.25965875,  0.17760944,  0.2725401 , -0.02872482, -0.32804632,\n",
      "        -0.18524037, -0.2600452 ,  0.07368761,  0.24932098,  0.11768887,\n",
      "         0.24320671],\n",
      "       [ 0.01433393, -0.04313008,  0.22616763, -0.17399126, -0.20477162,\n",
      "        -0.29956308, -0.3036771 , -0.3014893 , -0.30692622, -0.00423043,\n",
      "         0.02338267, -0.29599345,  0.06301264, -0.27608824,  0.05325615,\n",
      "        -0.24017604],\n",
      "       [-0.2221963 , -0.23590042,  0.23414151,  0.25897378, -0.0424179 ,\n",
      "        -0.28943634, -0.313162  , -0.07133368,  0.17522259,  0.06493042,\n",
      "         0.08078478,  0.1514611 ,  0.19370036,  0.09057578, -0.03503937,\n",
      "         0.11691743],\n",
      "       [ 0.10562503, -0.10951298, -0.04354466,  0.20551912, -0.33195493,\n",
      "         0.23494928, -0.13932212,  0.30226085,  0.09668224,  0.29528826,\n",
      "         0.23689923, -0.2556794 , -0.02685835,  0.01083195,  0.32375458,\n",
      "        -0.0353098 ],\n",
      "       [-0.3459107 , -0.2964436 ,  0.14862153,  0.32814312,  0.05744982,\n",
      "         0.07965608, -0.02345937,  0.14516222,  0.02687574, -0.23090433,\n",
      "        -0.29701054, -0.03931623, -0.15075625, -0.33612978, -0.11504072,\n",
      "         0.28997564],\n",
      "       [-0.34398413, -0.24415264, -0.29858637,  0.12977381, -0.34078938,\n",
      "         0.19339122,  0.25367364, -0.06030826,  0.05801506, -0.22090138,\n",
      "         0.31297955,  0.10153651,  0.14960165, -0.19136795, -0.14556836,\n",
      "        -0.01553308],\n",
      "       [-0.19130948,  0.33939567,  0.1126501 ,  0.11600436, -0.16461983,\n",
      "         0.05801756,  0.01109184,  0.01455341, -0.24845235,  0.23942997,\n",
      "        -0.27402782, -0.12540697,  0.20533174, -0.18656683, -0.3190354 ,\n",
      "        -0.06892629],\n",
      "       [-0.24389815, -0.18518698, -0.27106348,  0.15623176, -0.01969548,\n",
      "         0.18635173,  0.25150454,  0.18298711, -0.0379088 , -0.32093176,\n",
      "         0.30306166,  0.29551995,  0.30796558, -0.04230956, -0.06656293,\n",
      "         0.21827352],\n",
      "       [-0.22769758,  0.28929493,  0.17583558,  0.03537766, -0.09051408,\n",
      "         0.23273697, -0.20803311,  0.05795907,  0.318539  ,  0.17425367,\n",
      "        -0.31776044,  0.33665055, -0.00304947,  0.09348638,  0.07519158,\n",
      "        -0.08920705],\n",
      "       [ 0.18875544,  0.11504385, -0.3035373 ,  0.18255192, -0.08821519,\n",
      "         0.24973412, -0.34094158, -0.3158052 ,  0.1878125 ,  0.11135004,\n",
      "        -0.06715643,  0.17734572, -0.35252738,  0.1004691 ,  0.2233042 ,\n",
      "         0.05977962],\n",
      "       [ 0.03994838, -0.28968865,  0.07905506, -0.32026738,  0.2612885 ,\n",
      "        -0.21992798,  0.09990621,  0.16910757, -0.24328399,  0.2832841 ,\n",
      "        -0.32371742,  0.27625585,  0.2835695 , -0.01117834, -0.30220398,\n",
      "        -0.08347592],\n",
      "       [ 0.26450986, -0.1637962 ,  0.17867665,  0.21781641,  0.205255  ,\n",
      "        -0.25312647, -0.29407817,  0.16688268,  0.13943054,  0.22806114,\n",
      "        -0.14989772, -0.06473081,  0.17725639, -0.16635941, -0.06535296,\n",
      "         0.25705272],\n",
      "       [-0.21217541, -0.03181197,  0.28296226,  0.30651465,  0.0355722 ,\n",
      "         0.28314686,  0.17723462,  0.0291846 , -0.04911812, -0.18735068,\n",
      "         0.32210106, -0.09165051, -0.22096442, -0.32278875, -0.05544765,\n",
      "         0.15085925],\n",
      "       [-0.1914564 ,  0.07187708, -0.21246709,  0.3221144 ,  0.0024292 ,\n",
      "        -0.06557021, -0.20689498,  0.32914373, -0.01370864,  0.03169979,\n",
      "         0.09625465, -0.21023001,  0.00147233, -0.2362138 , -0.24458317,\n",
      "         0.11318864]], dtype=float32)>, <tf.Tensor: shape=(16,), dtype=float32, numpy=\n",
      "array([ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  8.4001003e-03,\n",
      "        1.0040469e-03, -2.6384736e-03, -2.7882066e-05, -6.3690105e-03,\n",
      "       -2.7877203e-04,  0.0000000e+00,  9.0285987e-03,  1.6700511e-03,\n",
      "       -3.3321842e-03, -6.1405553e-03,  0.0000000e+00, -7.0807873e-03],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(16, 16), dtype=float32, numpy=\n",
      "array([[ 3.64474505e-01,  3.29804838e-01, -3.85032892e-02,\n",
      "        -1.46745503e-01,  1.99305385e-01, -2.18631014e-01,\n",
      "         1.85620636e-01,  1.38906002e-01, -2.99792171e-01,\n",
      "        -7.83679187e-02, -3.11103553e-01, -4.04615045e-01,\n",
      "        -2.90963203e-01,  2.04275310e-01, -3.90546709e-01,\n",
      "         1.28892049e-01],\n",
      "       [ 1.73025310e-01,  2.07682803e-01, -2.47594178e-01,\n",
      "         2.00925469e-02,  5.45218326e-02, -3.65069598e-01,\n",
      "        -2.51369864e-01, -1.43341631e-01,  3.84133160e-01,\n",
      "         3.12610447e-01,  3.20578367e-02, -3.46430153e-01,\n",
      "        -3.96537542e-01, -4.12715375e-01,  1.33949786e-01,\n",
      "        -2.41714954e-01],\n",
      "       [ 4.04171586e-01,  3.52319449e-01, -7.24910870e-02,\n",
      "        -2.26054743e-01, -3.57390910e-01,  2.38881558e-01,\n",
      "        -9.98626575e-02, -1.54574914e-02, -1.85836777e-01,\n",
      "        -2.47594655e-01,  1.72885899e-02,  2.09152222e-01,\n",
      "        -1.62930265e-01, -4.34579067e-02, -3.06013614e-01,\n",
      "        -3.05245191e-01],\n",
      "       [-1.69253215e-01, -6.51957616e-02,  4.86177765e-02,\n",
      "        -2.30257884e-01, -1.61867842e-01,  5.74636683e-02,\n",
      "        -1.41344100e-01, -4.02208984e-01, -3.75471383e-01,\n",
      "        -1.36609077e-01,  2.44704172e-01, -3.05244535e-01,\n",
      "        -2.92219520e-01, -1.50618494e-01, -1.10646851e-01,\n",
      "         1.92907061e-02],\n",
      "       [-2.94131607e-01,  2.76839942e-01, -2.68588990e-01,\n",
      "        -3.88634980e-01,  7.67816156e-02, -1.71361193e-01,\n",
      "        -2.86074996e-01,  2.49696001e-01, -3.44545931e-01,\n",
      "        -3.79232556e-01, -2.71838963e-01, -4.11664456e-01,\n",
      "        -4.01151717e-01, -2.15014014e-02,  2.09488079e-01,\n",
      "         1.69209263e-03],\n",
      "       [-3.84006858e-01, -8.60325620e-02,  9.01848748e-02,\n",
      "        -1.23419814e-01,  1.13390997e-01,  4.06213939e-01,\n",
      "        -2.85817921e-01,  9.55425575e-02, -1.04792342e-01,\n",
      "        -1.06869033e-03, -3.88955176e-01, -1.73991267e-02,\n",
      "         2.74403632e-01,  1.79354072e-01,  1.05653450e-01,\n",
      "         2.34469175e-01],\n",
      "       [ 6.41961470e-02,  1.96361840e-01,  2.02461079e-01,\n",
      "        -4.06244174e-02, -3.45294595e-01, -3.93812805e-01,\n",
      "        -1.65353611e-01,  2.85520822e-01,  3.95372450e-01,\n",
      "         1.83990926e-01,  2.54831284e-01,  2.70032108e-01,\n",
      "         2.44106293e-01, -2.06791937e-01, -2.50893354e-01,\n",
      "         3.08806211e-01],\n",
      "       [-9.11044031e-02,  3.64277571e-01, -3.83844316e-01,\n",
      "        -6.87980950e-02,  2.50472665e-01,  3.68328959e-01,\n",
      "         5.56626655e-02, -2.27581666e-04,  2.76049614e-01,\n",
      "        -2.59100109e-01,  3.83826226e-01, -8.57318118e-02,\n",
      "        -1.35659948e-01,  3.89815807e-01, -2.88687021e-01,\n",
      "         3.16445798e-01],\n",
      "       [ 3.56801659e-01,  2.66673744e-01,  3.59885693e-01,\n",
      "        -2.80104399e-01,  3.33876997e-01, -4.00407255e-01,\n",
      "        -3.65430236e-01,  7.49406591e-02, -4.91014346e-02,\n",
      "        -3.31673920e-01, -2.95060664e-01,  3.87711465e-01,\n",
      "         3.01955998e-01, -2.63620555e-01, -4.07442153e-01,\n",
      "        -1.97994232e-01],\n",
      "       [-2.80515999e-02, -4.79236199e-03,  1.31745443e-01,\n",
      "        -7.04754293e-02,  3.95053439e-02, -1.60393551e-01,\n",
      "        -8.46445635e-02,  3.13313037e-01, -1.75024420e-01,\n",
      "         7.61742443e-02, -2.21656948e-01,  3.55578840e-01,\n",
      "         2.88711309e-01,  4.36344258e-02,  2.11893603e-01,\n",
      "         5.15706055e-02],\n",
      "       [-7.90231824e-02, -2.52712637e-01,  2.39235446e-01,\n",
      "        -2.91545898e-01,  2.51167595e-01,  3.41598913e-02,\n",
      "        -1.70551181e-01, -1.30589396e-01, -1.55017614e-01,\n",
      "        -1.33191913e-01,  2.64017731e-01,  1.27706662e-01,\n",
      "         4.66169044e-02, -3.21122408e-01, -7.66550452e-02,\n",
      "        -3.13041955e-01],\n",
      "       [-1.57856882e-01, -4.00949419e-01,  2.24851042e-01,\n",
      "         4.11441594e-01, -8.62797201e-02,  3.01116824e-01,\n",
      "         2.78581351e-01,  8.35011080e-02, -1.52454898e-01,\n",
      "        -8.04097299e-03, -1.42713934e-01,  1.02347821e-01,\n",
      "        -2.96125710e-01,  1.22784898e-01,  3.67769808e-01,\n",
      "         6.83371946e-02],\n",
      "       [-4.09510076e-01,  3.69308084e-01, -1.42869562e-01,\n",
      "         2.91343212e-01,  1.98718123e-02, -3.53789061e-01,\n",
      "        -1.51600361e-01, -1.95700243e-01,  3.23094755e-01,\n",
      "         3.57361734e-01,  7.15406016e-02,  6.95911348e-02,\n",
      "        -1.10453606e-01,  5.60356826e-02, -3.36486280e-01,\n",
      "         1.79379791e-01],\n",
      "       [-1.55637890e-01,  2.70180702e-01, -2.88060397e-01,\n",
      "         3.51680070e-02,  3.96123677e-02,  5.78821599e-02,\n",
      "        -2.82572210e-01,  3.51126820e-01, -2.88194686e-01,\n",
      "         7.90059045e-02, -9.26075578e-02, -3.90146464e-01,\n",
      "         2.58418798e-01, -6.97569177e-02, -2.28889972e-01,\n",
      "         2.06928417e-01],\n",
      "       [ 5.04613481e-02, -1.50335476e-01, -8.77166539e-02,\n",
      "         1.71972424e-01, -3.22437257e-01, -3.53117406e-01,\n",
      "        -2.05488294e-01, -3.48394513e-01, -4.58385572e-02,\n",
      "        -3.80891740e-01, -2.03231752e-01, -8.73698592e-02,\n",
      "         4.60012108e-02, -1.62569974e-02, -2.29425415e-01,\n",
      "         2.19864458e-01],\n",
      "       [ 2.99133658e-01,  3.42404723e-01,  1.84200406e-02,\n",
      "        -3.71545851e-01,  4.22129966e-02, -2.43401870e-01,\n",
      "         3.95612180e-01,  3.13699126e-01,  2.75634795e-01,\n",
      "         1.80334136e-01, -3.71233886e-03, -3.89723390e-01,\n",
      "         2.00457335e-01,  1.46930084e-01,  2.47939959e-01,\n",
      "        -2.56166637e-01]], dtype=float32)>, <tf.Tensor: shape=(16,), dtype=float32, numpy=\n",
      "array([-0.00044604, -0.00275665, -0.00058519, -0.00175867, -0.00708638,\n",
      "       -0.00175144, -0.00106112, -0.00156854,  0.00146786, -0.00333542,\n",
      "        0.0016278 , -0.00293885,  0.00011053, -0.00218915, -0.00060138,\n",
      "        0.00188025], dtype=float32)>, <tf.Tensor: shape=(16, 1), dtype=float32, numpy=\n",
      "array([[ 0.24306843],\n",
      "       [-0.3004592 ],\n",
      "       [-0.4746404 ],\n",
      "       [ 0.03536545],\n",
      "       [-0.44452754],\n",
      "       [ 0.22571212],\n",
      "       [ 0.3197318 ],\n",
      "       [ 0.42829892],\n",
      "       [ 0.15570752],\n",
      "       [-0.32096428],\n",
      "       [ 0.21497855],\n",
      "       [ 0.16674253],\n",
      "       [-0.01699083],\n",
      "       [-0.55299467],\n",
      "       [-0.26422808],\n",
      "       [ 0.16176315]], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.00230297], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "models = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K']\n",
    "avgWeight = FedAvg(models)\n",
    "print(avgWeight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testNewGlobal(weight):\n",
    "\n",
    "    test = pd.read_csv('./data/test.csv')\n",
    "    del test['Unnamed: 32']\n",
    "    print('Number of datapoints in Testing dataset: ',len(test))\n",
    "    X_test = test.iloc[:, 2:].values\n",
    "    y_test = test.iloc[:, 1].values\n",
    "\n",
    "    labelencoder = LabelEncoder()\n",
    "    y_test = labelencoder.fit_transform(y_test)\n",
    "\n",
    "#     sc = StandardScaler()\n",
    "#     X_test = sc.transform(X_test)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(16, activation='relu', input_dim=30))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.set_weights(weight)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    scores = model.evaluate(X_test, y_test)\n",
    "    print(\"Loss: \", scores[0])        #Loss\n",
    "    print(\"Accuracy: \", scores[1])    #Accuracy\n",
    "\n",
    "    #Saving Model\n",
    "    model.save(\"./weights/output.h5\")\n",
    "    return scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints in Testing dataset:  75\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x14a5b9e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 5.1236 - accuracy: 0.2533\n",
      "Loss:  5.1235551834106445\n",
      "Accuracy:  0.25333333015441895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.25333333015441895"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testNewGlobal(avgWeight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
