{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://www.kaggle.com/sharp1/malaria-cells-classification-through-keras\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\n",
    "import pandas as pd\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(filepath, label):\n",
    "    cells = []\n",
    "    labels = []\n",
    "    file = os.listdir(filepath)\n",
    "    for img in file:\n",
    "        try:\n",
    "            image = cv2.imread(filepath + img)\n",
    "            image_from_array = Image.fromarray(image, 'RGB')\n",
    "            size_image = image_from_array.resize((50, 50))\n",
    "            cells.append(np.array(size_image))\n",
    "            labels.append(label)\n",
    "        except AttributeError as e:\n",
    "            print('Skipping file: ', img, e)\n",
    "    print(len(cells), ' Data Points Read!')\n",
    "    return np.array(cells), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2740  Data Points Read!\n",
      "2783  Data Points Read!\n"
     ]
    }
   ],
   "source": [
    "TestParasitizedCells, TestParasitizedLabels = readData('./input/fed/test/Parasitized/', 1)\n",
    "TestUninfectedCells, TestUninfectedLabels  = readData('./input/fed/test/Uninfected/', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genesis_train(file):\n",
    "    \n",
    "    print('Reading Training Data')\n",
    "    \n",
    "    ParasitizedCells, ParasitizedLabels = readData(file + '/Parasitized/', 1)\n",
    "    UninfectedCells, UninfectedLabels  = readData(file + '/Uninfected/', 0)\n",
    "    \n",
    "    Cells = np.concatenate((ParasitizedCells, UninfectedCells))\n",
    "    Labels = np.concatenate((ParasitizedLabels, UninfectedLabels))\n",
    "    \n",
    "    print('Reading Testing Data')\n",
    "    \n",
    "    TestCells = np.concatenate((TestParasitizedCells, TestUninfectedCells))\n",
    "    TestLabels = np.concatenate((TestParasitizedLabels, TestUninfectedLabels))\n",
    "    \n",
    "    s = np.arange(Cells.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    Cells = Cells[s]\n",
    "    Labels = Labels[s]\n",
    "    \n",
    "    sTest = np.arange(TestCells.shape[0])\n",
    "    np.random.shuffle(sTest)\n",
    "    TestCells = TestCells[sTest]\n",
    "    TestLabels = TestLabels[sTest]\n",
    "    \n",
    "    num_classes=len(np.unique(Labels))\n",
    "    len_data=len(Cells)\n",
    "    print(len_data, ' Data Points')\n",
    "    \n",
    "    (x_train,x_test)=Cells, TestCells\n",
    "    (y_train,y_test)=Labels, TestLabels\n",
    "    \n",
    "    # Since we're working on image data, we normalize data by divinding 255.\n",
    "    x_train = x_train.astype('float32')/255 \n",
    "    x_test = x_test.astype('float32')/255\n",
    "    train_len=len(x_train)\n",
    "    test_len=len(x_test)\n",
    "    \n",
    "    #Doing One hot encoding as classifier has multiple classes\n",
    "    y_train=keras.utils.to_categorical(y_train,num_classes)\n",
    "    y_test=keras.utils.to_categorical(y_test,num_classes)\n",
    "    \n",
    "    #creating sequential model\n",
    "    model=Sequential()\n",
    "    model.add(Conv2D(filters=16,kernel_size=2,padding=\"same\",activation=\"relu\",input_shape=(50,50,3)))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Conv2D(filters=64,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(500,activation=\"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(2,activation=\"softmax\"))#2 represent output layer neurons \n",
    "#     model.summary()\n",
    "\n",
    "    # compile the model with loss as categorical_crossentropy and using adam optimizer\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    #Fit the model with min batch size as 50[can tune batch size to some factor of 2^power ] \n",
    "    model.fit(x_train, y_train, batch_size=100, epochs=3, verbose=1)\n",
    "    \n",
    "    scores = model.evaluate(x_test, y_test)\n",
    "    print(\"Loss: \", scores[0])        #Loss\n",
    "    print(\"Accuracy: \", scores[1])    #Accuracy\n",
    "\n",
    "    #Saving Model\n",
    "    model.save(\"./output.h5\")\n",
    "    return len_data, scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_train(file, d):\n",
    "    \n",
    "    print('Reading Training Data')\n",
    "    ParasitizedCells, ParasitizedLabels = readData(file + '/Parasitized/', 1)\n",
    "    UninfectedCells, UninfectedLabels  = readData(file + '/Uninfected/', 0)\n",
    "    \n",
    "    Cells = np.concatenate((ParasitizedCells, UninfectedCells))\n",
    "    Labels = np.concatenate((ParasitizedLabels, UninfectedLabels))\n",
    "    \n",
    "    print('Reading Testing Data')\n",
    "    \n",
    "    TestCells = np.concatenate((TestParasitizedCells, TestUninfectedCells))\n",
    "    TestLabels = np.concatenate((TestParasitizedLabels, TestUninfectedLabels))\n",
    "    \n",
    "    s = np.arange(Cells.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    Cells = Cells[s]\n",
    "    Labels = Labels[s]\n",
    "    \n",
    "    sTest = np.arange(TestCells.shape[0])\n",
    "    np.random.shuffle(sTest)\n",
    "    TestCells = TestCells[sTest]\n",
    "    TestLabels = TestLabels[sTest]\n",
    "    \n",
    "    num_classes=len(np.unique(Labels))\n",
    "    len_data=len(Cells)\n",
    "    print(len_data, ' Data Points')\n",
    "    \n",
    "    (x_train,x_test)=Cells, TestCells\n",
    "    (y_train,y_test)=Labels, TestLabels\n",
    "    \n",
    "    # Since we're working on image data, we normalize data by divinding 255.\n",
    "    x_train = x_train.astype('float32')/255 \n",
    "    x_test = x_test.astype('float32')/255\n",
    "    train_len=len(x_train)\n",
    "    test_len=len(x_test)\n",
    "    \n",
    "    #Doing One hot encoding as classifier has multiple classes\n",
    "    y_train=keras.utils.to_categorical(y_train,num_classes)\n",
    "    y_test=keras.utils.to_categorical(y_test,num_classes)\n",
    "    \n",
    "    #creating sequential model\n",
    "    model=Sequential()\n",
    "    model.add(Conv2D(filters=16,kernel_size=2,padding=\"same\",activation=\"relu\",input_shape=(50,50,3)))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Conv2D(filters=64,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(500,activation=\"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(2,activation=\"softmax\"))#2 represent output layer neurons \n",
    "    # model.summary()\n",
    "\n",
    "    model.load_weights(\"./output.h5\")\n",
    "    \n",
    "    # compile the model with loss as categorical_crossentropy and using adam optimizer\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    #Fit the model with min batch size as 50[can tune batch size to some factor of 2^power ] \n",
    "    model.fit(x_train, y_train, batch_size=100, epochs=3, verbose=1)\n",
    "    \n",
    "    \n",
    "    scores = model.evaluate(x_test, y_test)\n",
    "    print(\"Loss: \", scores[0])        #Loss\n",
    "    print(\"Accuracy: \", scores[1])    #Accuracy\n",
    "\n",
    "    #Saving Model\n",
    "    model.save(\"./weights/\" + str(d) + \".h5\")\n",
    "    return len_data, scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Training Data\n",
      "686  Data Points Read!\n",
      "696  Data Points Read!\n",
      "Reading Testing Data\n",
      "1382  Data Points\n",
      "Epoch 1/3\n",
      "14/14 [==============================] - 2s 101ms/step - loss: 0.7168 - accuracy: 0.4966\n",
      "Epoch 2/3\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.6832 - accuracy: 0.5428\n",
      "Epoch 3/3\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 0.6691 - accuracy: 0.5947\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.6367 - accuracy: 0.6527\n",
      "Loss:  0.6367493867874146\n",
      "Accuracy:  0.6527249813079834\n",
      "Reading Training Data\n",
      "528  Data Points Read!\n",
      "533  Data Points Read!\n",
      "Reading Testing Data\n",
      "1061  Data Points\n",
      "Epoch 1/3\n",
      "11/11 [==============================] - 2s 97ms/step - loss: 0.6256 - accuracy: 0.6457\n",
      "Epoch 2/3\n",
      "11/11 [==============================] - 1s 97ms/step - loss: 0.5872 - accuracy: 0.7047\n",
      "Epoch 3/3\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.5792 - accuracy: 0.7095\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.5931 - accuracy: 0.6719\n",
      "Loss:  0.5931140184402466\n",
      "Accuracy:  0.6719174385070801\n",
      "Reading Training Data\n",
      "522  Data Points Read!\n",
      "528  Data Points Read!\n",
      "Reading Testing Data\n",
      "1050  Data Points\n",
      "Epoch 1/3\n",
      "11/11 [==============================] - 2s 98ms/step - loss: 0.6582 - accuracy: 0.6073\n",
      "Epoch 2/3\n",
      "11/11 [==============================] - 1s 97ms/step - loss: 0.6444 - accuracy: 0.6338\n",
      "Epoch 3/3\n",
      "11/11 [==============================] - 1s 96ms/step - loss: 0.5989 - accuracy: 0.6797\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.5853 - accuracy: 0.6913\n",
      "Loss:  0.5853269696235657\n",
      "Accuracy:  0.6912909746170044\n",
      "Reading Training Data\n",
      "692  Data Points Read!\n",
      "655  Data Points Read!\n",
      "Reading Testing Data\n",
      "1347  Data Points\n",
      "Epoch 1/3\n",
      "14/14 [==============================] - 2s 102ms/step - loss: 0.6261 - accuracy: 0.6484\n",
      "Epoch 2/3\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.5881 - accuracy: 0.6902\n",
      "Epoch 3/3\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.6080 - accuracy: 0.6759\n",
      "173/173 [==============================] - 2s 10ms/step - loss: 0.5811 - accuracy: 0.6960\n",
      "Loss:  0.5811020135879517\n",
      "Accuracy:  0.6959985494613647\n",
      "Reading Training Data\n",
      "448  Data Points Read!\n",
      "410  Data Points Read!\n",
      "Reading Testing Data\n",
      "858  Data Points\n",
      "Epoch 1/3\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.6442 - accuracy: 0.6241\n",
      "Epoch 2/3\n",
      "9/9 [==============================] - 1s 101ms/step - loss: 0.6162 - accuracy: 0.6812\n",
      "Epoch 3/3\n",
      "9/9 [==============================] - 1s 98ms/step - loss: 0.5690 - accuracy: 0.7147\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.6002 - accuracy: 0.7079\n",
      "Loss:  0.6002377867698669\n",
      "Accuracy:  0.7079485654830933\n",
      "Reading Training Data\n",
      "838  Data Points Read!\n",
      "838  Data Points Read!\n",
      "Reading Testing Data\n",
      "1676  Data Points\n",
      "Epoch 1/3\n",
      "17/17 [==============================] - 2s 97ms/step - loss: 0.6493 - accuracy: 0.5964\n",
      "Epoch 2/3\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 0.6290 - accuracy: 0.6302\n",
      "Epoch 3/3\n",
      "17/17 [==============================] - 2s 103ms/step - loss: 0.5672 - accuracy: 0.7053\n",
      "173/173 [==============================] - 2s 10ms/step - loss: 0.5493 - accuracy: 0.7239\n",
      "Loss:  0.5492643117904663\n",
      "Accuracy:  0.7238819599151611\n",
      "Reading Training Data\n",
      "599  Data Points Read!\n",
      "567  Data Points Read!\n",
      "Reading Testing Data\n",
      "1166  Data Points\n",
      "Epoch 1/3\n",
      "12/12 [==============================] - 2s 107ms/step - loss: 0.6654 - accuracy: 0.6126\n",
      "Epoch 2/3\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 0.6226 - accuracy: 0.6826\n",
      "Epoch 3/3\n",
      "12/12 [==============================] - 1s 101ms/step - loss: 0.6030 - accuracy: 0.6854\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.5781 - accuracy: 0.7052\n",
      "Loss:  0.578075647354126\n",
      "Accuracy:  0.7052326798439026\n",
      "Reading Training Data\n",
      "418  Data Points Read!\n",
      "395  Data Points Read!\n",
      "Reading Testing Data\n",
      "813  Data Points\n",
      "Epoch 1/3\n",
      "9/9 [==============================] - 1s 101ms/step - loss: 0.6826 - accuracy: 0.5701\n",
      "Epoch 2/3\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6531 - accuracy: 0.6266\n",
      "Epoch 3/3\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.6223 - accuracy: 0.6612\n",
      "173/173 [==============================] - 2s 10ms/step - loss: 0.5960 - accuracy: 0.6926\n",
      "Loss:  0.5959714651107788\n",
      "Accuracy:  0.6925584077835083\n",
      "Reading Training Data\n",
      "716  Data Points Read!\n",
      "729  Data Points Read!\n",
      "Reading Testing Data\n",
      "1445  Data Points\n",
      "Epoch 1/3\n",
      "15/15 [==============================] - 2s 95ms/step - loss: 0.6583 - accuracy: 0.6097\n",
      "Epoch 2/3\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 0.6194 - accuracy: 0.6757\n",
      "Epoch 3/3\n",
      "15/15 [==============================] - 1s 97ms/step - loss: 0.5887 - accuracy: 0.6797\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.5746 - accuracy: 0.7154\n",
      "Loss:  0.5745799541473389\n",
      "Accuracy:  0.7153720855712891\n",
      "Reading Training Data\n",
      "530  Data Points Read!\n",
      "572  Data Points Read!\n",
      "Reading Testing Data\n",
      "1102  Data Points\n",
      "Epoch 1/3\n",
      "12/12 [==============================] - 2s 97ms/step - loss: 0.6529 - accuracy: 0.6317\n",
      "Epoch 2/3\n",
      "12/12 [==============================] - 1s 98ms/step - loss: 0.6158 - accuracy: 0.6731\n",
      "Epoch 3/3\n",
      "12/12 [==============================] - 1s 106ms/step - loss: 0.6772 - accuracy: 0.5966\n",
      "173/173 [==============================] - 2s 10ms/step - loss: 0.6083 - accuracy: 0.6692\n",
      "Loss:  0.6082690954208374\n",
      "Accuracy:  0.6692014932632446\n",
      "Reading Training Data\n",
      "695  Data Points Read!\n",
      "701  Data Points Read!\n",
      "Reading Testing Data\n",
      "1396  Data Points\n",
      "Epoch 1/3\n",
      "14/14 [==============================] - 2s 110ms/step - loss: 0.6486 - accuracy: 0.6192\n",
      "Epoch 2/3\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 0.6250 - accuracy: 0.6530\n",
      "Epoch 3/3\n",
      "14/14 [==============================] - 1s 105ms/step - loss: 0.5864 - accuracy: 0.6884\n",
      "173/173 [==============================] - 2s 10ms/step - loss: 0.5701 - accuracy: 0.7078\n",
      "Loss:  0.5701382756233215\n",
      "Accuracy:  0.7077675461769104\n",
      "Reading Training Data\n",
      "557  Data Points Read!\n",
      "577  Data Points Read!\n",
      "Reading Testing Data\n",
      "1134  Data Points\n",
      "Epoch 1/3\n",
      "12/12 [==============================] - 2s 92ms/step - loss: 0.6507 - accuracy: 0.6103\n",
      "Epoch 2/3\n",
      "12/12 [==============================] - 1s 94ms/step - loss: 0.6362 - accuracy: 0.6166\n",
      "Epoch 3/3\n",
      "12/12 [==============================] - 1s 96ms/step - loss: 0.6388 - accuracy: 0.6211\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.5944 - accuracy: 0.6775\n",
      "Loss:  0.5944010615348816\n",
      "Accuracy:  0.6775303483009338\n",
      "Reading Training Data\n",
      "827  Data Points Read!\n",
      "796  Data Points Read!\n",
      "Reading Testing Data\n",
      "1623  Data Points\n",
      "Epoch 1/3\n",
      "17/17 [==============================] - 2s 90ms/step - loss: 0.6524 - accuracy: 0.6235\n",
      "Epoch 2/3\n",
      "17/17 [==============================] - 2s 95ms/step - loss: 0.5949 - accuracy: 0.7004\n",
      "Epoch 3/3\n",
      "17/17 [==============================] - 2s 101ms/step - loss: 0.5819 - accuracy: 0.6965\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.5550 - accuracy: 0.7320\n",
      "Loss:  0.5550136566162109\n",
      "Accuracy:  0.7320296764373779\n",
      "Reading Training Data\n",
      "395  Data Points Read!\n",
      "425  Data Points Read!\n",
      "Reading Testing Data\n",
      "820  Data Points\n",
      "Epoch 1/3\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.6329 - accuracy: 0.6485\n",
      "Epoch 2/3\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.5992 - accuracy: 0.6981\n",
      "Epoch 3/3\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.5568 - accuracy: 0.7292\n",
      "173/173 [==============================] - 2s 10ms/step - loss: 0.6237 - accuracy: 0.6801\n",
      "Loss:  0.62367182970047\n",
      "Accuracy:  0.6800651550292969\n",
      "Reading Training Data\n",
      "513  Data Points Read!\n",
      "528  Data Points Read!\n",
      "Reading Testing Data\n",
      "1041  Data Points\n",
      "Epoch 1/3\n",
      "11/11 [==============================] - 2s 102ms/step - loss: 0.6584 - accuracy: 0.6073\n",
      "Epoch 2/3\n",
      "11/11 [==============================] - 1s 99ms/step - loss: 0.6297 - accuracy: 0.6608\n",
      "Epoch 3/3\n",
      "11/11 [==============================] - 1s 98ms/step - loss: 0.5831 - accuracy: 0.6983\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.5770 - accuracy: 0.7101\n",
      "Loss:  0.5769632458686829\n",
      "Accuracy:  0.7101213335990906\n",
      "Reading Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284  Data Points Read!\n",
      "281  Data Points Read!\n",
      "Reading Testing Data\n",
      "565  Data Points\n",
      "Epoch 1/3\n",
      "6/6 [==============================] - 1s 90ms/step - loss: 0.6349 - accuracy: 0.6571\n",
      "Epoch 2/3\n",
      "6/6 [==============================] - 1s 87ms/step - loss: 0.6193 - accuracy: 0.6703\n",
      "Epoch 3/3\n",
      "6/6 [==============================] - 1s 87ms/step - loss: 0.6002 - accuracy: 0.6901\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.6365 - accuracy: 0.6292\n",
      "Loss:  0.6365188360214233\n",
      "Accuracy:  0.6291870474815369\n",
      "Reading Training Data\n",
      "412  Data Points Read!\n",
      "416  Data Points Read!\n",
      "Reading Testing Data\n",
      "828  Data Points\n",
      "Epoch 1/3\n",
      "9/9 [==============================] - 1s 105ms/step - loss: 0.6749 - accuracy: 0.5594\n",
      "Epoch 2/3\n",
      "9/9 [==============================] - 1s 103ms/step - loss: 0.6402 - accuracy: 0.6354\n",
      "Epoch 3/3\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6102 - accuracy: 0.6720\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.5949 - accuracy: 0.6940\n",
      "Loss:  0.5948529243469238\n",
      "Accuracy:  0.6940068602561951\n",
      "Reading Training Data\n",
      "417  Data Points Read!\n",
      "414  Data Points Read!\n",
      "Reading Testing Data\n",
      "831  Data Points\n",
      "Epoch 1/3\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.6479 - accuracy: 0.6060\n",
      "Epoch 2/3\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.6058 - accuracy: 0.6579\n",
      "Epoch 3/3\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.5919 - accuracy: 0.6599\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.5907 - accuracy: 0.6897\n",
      "Loss:  0.5907285213470459\n",
      "Accuracy:  0.68966144323349\n",
      "Reading Training Data\n",
      "269  Data Points Read!\n",
      "252  Data Points Read!\n",
      "Reading Testing Data\n",
      "521  Data Points\n",
      "Epoch 1/3\n",
      "6/6 [==============================] - 1s 96ms/step - loss: 0.6713 - accuracy: 0.5925\n",
      "Epoch 2/3\n",
      "6/6 [==============================] - 1s 97ms/step - loss: 0.6461 - accuracy: 0.5988\n",
      "Epoch 3/3\n",
      "6/6 [==============================] - 1s 94ms/step - loss: 0.6282 - accuracy: 0.6475\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.6206 - accuracy: 0.6690\n",
      "Loss:  0.620616614818573\n",
      "Accuracy:  0.6690204739570618\n",
      "Reading Training Data\n",
      "407  Data Points Read!\n",
      "407  Data Points Read!\n",
      "Reading Testing Data\n",
      "814  Data Points\n",
      "Epoch 1/3\n",
      "9/9 [==============================] - 2s 90ms/step - loss: 0.6436 - accuracy: 0.6309\n",
      "Epoch 2/3\n",
      "9/9 [==============================] - 1s 83ms/step - loss: 0.6018 - accuracy: 0.6860\n",
      "Epoch 3/3\n",
      "9/9 [==============================] - 1s 82ms/step - loss: 0.5708 - accuracy: 0.7089\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.5925 - accuracy: 0.6734\n",
      "Loss:  0.5924577713012695\n",
      "Accuracy:  0.6733659505844116\n",
      "Reading Training Data\n",
      "286  Data Points Read!\n",
      "276  Data Points Read!\n",
      "Reading Testing Data\n",
      "562  Data Points\n",
      "Epoch 1/3\n",
      "6/6 [==============================] - 1s 98ms/step - loss: 0.6642 - accuracy: 0.5805\n",
      "Epoch 2/3\n",
      "6/6 [==============================] - 1s 97ms/step - loss: 0.6341 - accuracy: 0.6476\n",
      "Epoch 3/3\n",
      "6/6 [==============================] - 1s 87ms/step - loss: 0.6099 - accuracy: 0.6909\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.6154 - accuracy: 0.6542\n",
      "Loss:  0.6153764724731445\n",
      "Accuracy:  0.6541734337806702\n"
     ]
    }
   ],
   "source": [
    "FLAccuracy = {}\n",
    "# FLAccuracy['Complete Dataset'] = genesis_train('./input/cell_images')\n",
    "FLAccuracy['Genesis'] = genesis_train('./input/fed/genesis')\n",
    "FLAccuracy['d1'] = update_train('./input/fed/d1', 'd1')\n",
    "FLAccuracy['d2'] = update_train('./input/fed/d2', 'd2')\n",
    "FLAccuracy['d3'] = update_train('./input/fed/d3', 'd3')\n",
    "FLAccuracy['d4'] = update_train('./input/fed/d4', 'd4')\n",
    "FLAccuracy['d5'] = update_train('./input/fed/d5', 'd5')\n",
    "FLAccuracy['d6'] = update_train('./input/fed/d6', 'd6')\n",
    "FLAccuracy['d7'] = update_train('./input/fed/d7', 'd7')\n",
    "FLAccuracy['d8'] = update_train('./input/fed/d8', 'd8')\n",
    "FLAccuracy['d9'] = update_train('./input/fed/d9', 'd9')\n",
    "FLAccuracy['d10'] = update_train('./input/fed/d10', 'd10')\n",
    "FLAccuracy['d11'] = update_train('./input/fed/d11', 'd11')\n",
    "FLAccuracy['d12'] = update_train('./input/fed/d12', 'd12')\n",
    "FLAccuracy['d13'] = update_train('./input/fed/d13', 'd13')\n",
    "FLAccuracy['d14'] = update_train('./input/fed/d14', 'd14')\n",
    "FLAccuracy['d15'] = update_train('./input/fed/d15', 'd15')\n",
    "FLAccuracy['d16'] = update_train('./input/fed/d16', 'd16')\n",
    "FLAccuracy['d17'] = update_train('./input/fed/d17', 'd17')\n",
    "FLAccuracy['d18'] = update_train('./input/fed/d18', 'd18')\n",
    "FLAccuracy['d19'] = update_train('./input/fed/d19', 'd19')\n",
    "FLAccuracy['d20'] = update_train('./input/fed/d20', 'd20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Genesis': (1382, 0.6527249813079834),\n",
       " 'd1': (1061, 0.6719174385070801),\n",
       " 'd2': (1050, 0.6912909746170044),\n",
       " 'd3': (1347, 0.6959985494613647),\n",
       " 'd4': (858, 0.7079485654830933),\n",
       " 'd5': (1676, 0.7238819599151611),\n",
       " 'd6': (1166, 0.7052326798439026),\n",
       " 'd7': (813, 0.6925584077835083),\n",
       " 'd8': (1445, 0.7153720855712891),\n",
       " 'd9': (1102, 0.6692014932632446),\n",
       " 'd10': (1396, 0.7077675461769104),\n",
       " 'd11': (1134, 0.6775303483009338),\n",
       " 'd12': (1623, 0.7320296764373779),\n",
       " 'd13': (820, 0.6800651550292969),\n",
       " 'd14': (1041, 0.7101213335990906),\n",
       " 'd15': (565, 0.6291870474815369),\n",
       " 'd16': (828, 0.6940068602561951),\n",
       " 'd17': (831, 0.68966144323349),\n",
       " 'd18': (521, 0.6690204739570618),\n",
       " 'd19': (814, 0.6733659505844116),\n",
       " 'd20': (562, 0.6541734337806702)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FLAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataSize</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Genesis</th>\n",
       "      <td>1382</td>\n",
       "      <td>0.652725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d1</th>\n",
       "      <td>1061</td>\n",
       "      <td>0.671917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2</th>\n",
       "      <td>1050</td>\n",
       "      <td>0.691291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d3</th>\n",
       "      <td>1347</td>\n",
       "      <td>0.695999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d4</th>\n",
       "      <td>858</td>\n",
       "      <td>0.707949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d5</th>\n",
       "      <td>1676</td>\n",
       "      <td>0.723882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d6</th>\n",
       "      <td>1166</td>\n",
       "      <td>0.705233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d7</th>\n",
       "      <td>813</td>\n",
       "      <td>0.692558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d8</th>\n",
       "      <td>1445</td>\n",
       "      <td>0.715372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d9</th>\n",
       "      <td>1102</td>\n",
       "      <td>0.669201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d10</th>\n",
       "      <td>1396</td>\n",
       "      <td>0.707768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d11</th>\n",
       "      <td>1134</td>\n",
       "      <td>0.677530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d12</th>\n",
       "      <td>1623</td>\n",
       "      <td>0.732030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d13</th>\n",
       "      <td>820</td>\n",
       "      <td>0.680065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d14</th>\n",
       "      <td>1041</td>\n",
       "      <td>0.710121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d15</th>\n",
       "      <td>565</td>\n",
       "      <td>0.629187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d16</th>\n",
       "      <td>828</td>\n",
       "      <td>0.694007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d17</th>\n",
       "      <td>831</td>\n",
       "      <td>0.689661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d18</th>\n",
       "      <td>521</td>\n",
       "      <td>0.669020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d19</th>\n",
       "      <td>814</td>\n",
       "      <td>0.673366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d20</th>\n",
       "      <td>562</td>\n",
       "      <td>0.654173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DataSize  Accuracy\n",
       "Genesis      1382  0.652725\n",
       "d1           1061  0.671917\n",
       "d2           1050  0.691291\n",
       "d3           1347  0.695999\n",
       "d4            858  0.707949\n",
       "d5           1676  0.723882\n",
       "d6           1166  0.705233\n",
       "d7            813  0.692558\n",
       "d8           1445  0.715372\n",
       "d9           1102  0.669201\n",
       "d10          1396  0.707768\n",
       "d11          1134  0.677530\n",
       "d12          1623  0.732030\n",
       "d13           820  0.680065\n",
       "d14          1041  0.710121\n",
       "d15           565  0.629187\n",
       "d16           828  0.694007\n",
       "d17           831  0.689661\n",
       "d18           521  0.669020\n",
       "d19           814  0.673366\n",
       "d20           562  0.654173"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FLAccuracyDF = pd.DataFrame.from_dict(FLAccuracy, orient='index', columns=['DataSize', 'Accuracy'])\n",
    "FLAccuracyDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Genesis', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8', 'd9', 'd10',\n",
       "       'd11', 'd12', 'd13', 'd14', 'd15', 'd16', 'd17', 'd18', 'd19', 'd20'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FLAccuracyDF.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of data points in this round:  22035\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for w in FLAccuracy:\n",
    "    if 'Complete' in w:\n",
    "        continue\n",
    "    n += FLAccuracy[w][0]\n",
    "print('Total number of data points in this round: ', n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAccuracyDF['Weightage'] = FLAccuracyDF['DataSize'].apply(lambda x: x/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataSize</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Weightage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Genesis</th>\n",
       "      <td>1382</td>\n",
       "      <td>0.652725</td>\n",
       "      <td>0.062718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d1</th>\n",
       "      <td>1061</td>\n",
       "      <td>0.671917</td>\n",
       "      <td>0.048151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2</th>\n",
       "      <td>1050</td>\n",
       "      <td>0.691291</td>\n",
       "      <td>0.047651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d3</th>\n",
       "      <td>1347</td>\n",
       "      <td>0.695999</td>\n",
       "      <td>0.061130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d4</th>\n",
       "      <td>858</td>\n",
       "      <td>0.707949</td>\n",
       "      <td>0.038938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d5</th>\n",
       "      <td>1676</td>\n",
       "      <td>0.723882</td>\n",
       "      <td>0.076061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d6</th>\n",
       "      <td>1166</td>\n",
       "      <td>0.705233</td>\n",
       "      <td>0.052916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d7</th>\n",
       "      <td>813</td>\n",
       "      <td>0.692558</td>\n",
       "      <td>0.036896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d8</th>\n",
       "      <td>1445</td>\n",
       "      <td>0.715372</td>\n",
       "      <td>0.065577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d9</th>\n",
       "      <td>1102</td>\n",
       "      <td>0.669201</td>\n",
       "      <td>0.050011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d10</th>\n",
       "      <td>1396</td>\n",
       "      <td>0.707768</td>\n",
       "      <td>0.063354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d11</th>\n",
       "      <td>1134</td>\n",
       "      <td>0.677530</td>\n",
       "      <td>0.051464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d12</th>\n",
       "      <td>1623</td>\n",
       "      <td>0.732030</td>\n",
       "      <td>0.073656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d13</th>\n",
       "      <td>820</td>\n",
       "      <td>0.680065</td>\n",
       "      <td>0.037214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d14</th>\n",
       "      <td>1041</td>\n",
       "      <td>0.710121</td>\n",
       "      <td>0.047243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d15</th>\n",
       "      <td>565</td>\n",
       "      <td>0.629187</td>\n",
       "      <td>0.025641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d16</th>\n",
       "      <td>828</td>\n",
       "      <td>0.694007</td>\n",
       "      <td>0.037577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d17</th>\n",
       "      <td>831</td>\n",
       "      <td>0.689661</td>\n",
       "      <td>0.037713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d18</th>\n",
       "      <td>521</td>\n",
       "      <td>0.669020</td>\n",
       "      <td>0.023644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d19</th>\n",
       "      <td>814</td>\n",
       "      <td>0.673366</td>\n",
       "      <td>0.036941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d20</th>\n",
       "      <td>562</td>\n",
       "      <td>0.654173</td>\n",
       "      <td>0.025505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DataSize  Accuracy  Weightage\n",
       "Genesis      1382  0.652725   0.062718\n",
       "d1           1061  0.671917   0.048151\n",
       "d2           1050  0.691291   0.047651\n",
       "d3           1347  0.695999   0.061130\n",
       "d4            858  0.707949   0.038938\n",
       "d5           1676  0.723882   0.076061\n",
       "d6           1166  0.705233   0.052916\n",
       "d7            813  0.692558   0.036896\n",
       "d8           1445  0.715372   0.065577\n",
       "d9           1102  0.669201   0.050011\n",
       "d10          1396  0.707768   0.063354\n",
       "d11          1134  0.677530   0.051464\n",
       "d12          1623  0.732030   0.073656\n",
       "d13           820  0.680065   0.037214\n",
       "d14          1041  0.710121   0.047243\n",
       "d15           565  0.629187   0.025641\n",
       "d16           828  0.694007   0.037577\n",
       "d17           831  0.689661   0.037713\n",
       "d18           521  0.669020   0.023644\n",
       "d19           814  0.673366   0.036941\n",
       "d20           562  0.654173   0.025505"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FLAccuracyDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(weight, scaler):\n",
    "    scaledWeights = []\n",
    "    for i in range(len(weight)):\n",
    "        scaledWeights.append(scaler * weight[i])\n",
    "    return scaledWeights\n",
    "\n",
    "def getScaledWeight(d, scaler):\n",
    "    \n",
    "    #creating sequential model\n",
    "    model=Sequential()\n",
    "    model.add(Conv2D(filters=16,kernel_size=2,padding=\"same\",activation=\"relu\",input_shape=(50,50,3)))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Conv2D(filters=64,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(500,activation=\"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(2,activation=\"softmax\"))#2 represent output layer neurons \n",
    "    \n",
    "    fpath = \"./weights/\"+d+\".h5\"\n",
    "    model.load_weights(fpath)\n",
    "    weight = model.get_weights()\n",
    "    scaledWeight = scale(weight, scaler)\n",
    "\n",
    "    return scaledWeight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgWeights(scaledWeights):\n",
    "    avg = list()\n",
    "    for weight_list_tuple in zip(*scaledWeights):\n",
    "        layer_mean = tf.math.reduce_sum(weight_list_tuple, axis=0)\n",
    "        avg.append(layer_mean)\n",
    "    return avg\n",
    "\n",
    "def FedAvg(models):\n",
    "    \n",
    "    scaledWeights = []\n",
    "    for m in models:\n",
    "        scaledWeights.append(getScaledWeight(m, FLAccuracyDF.loc[m]['Weightage']))\n",
    "    avgWeight = avgWeights(scaledWeights)\n",
    "    return avgWeight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(2, 2, 3, 16), dtype=float32, numpy=\n",
      "array([[[[-0.01278405,  0.1480821 , -0.18427667,  0.02990142,\n",
      "          -0.09053817,  0.25427815,  0.19300961,  0.01253956,\n",
      "          -0.04350141, -0.06555912, -0.04546903, -0.15567143,\n",
      "           0.25756803,  0.14353284, -0.04832796,  0.19892983],\n",
      "         [ 0.2230724 ,  0.20676409, -0.23267385, -0.14192563,\n",
      "           0.05304413, -0.02690437,  0.05242201,  0.1132592 ,\n",
      "          -0.02114039,  0.08733422,  0.05635345, -0.01730666,\n",
      "           0.05016673, -0.04955962,  0.21671656,  0.08668724],\n",
      "         [-0.17331281,  0.18996766,  0.17913473, -0.10117243,\n",
      "           0.15795584,  0.23815058, -0.08311746, -0.2694573 ,\n",
      "           0.10260476, -0.06708112,  0.00096423,  0.07271762,\n",
      "          -0.2258053 ,  0.17079078, -0.17367807,  0.09707605]],\n",
      "\n",
      "        [[ 0.20702285,  0.05424436,  0.20706458, -0.17511858,\n",
      "           0.11578032, -0.11868624,  0.25299823, -0.09753612,\n",
      "           0.24851714,  0.13223283, -0.21930216, -0.24676576,\n",
      "          -0.17106414, -0.19285677,  0.09867753, -0.03754777],\n",
      "         [-0.20034246,  0.02061405, -0.1091039 ,  0.20662086,\n",
      "          -0.13075687,  0.021385  , -0.25526583, -0.21117364,\n",
      "           0.22426157,  0.1977833 , -0.15478416,  0.13460235,\n",
      "          -0.19702548,  0.0013221 ,  0.10742623, -0.06422649],\n",
      "         [ 0.1149735 , -0.03144117, -0.23596796, -0.19419666,\n",
      "           0.21343002, -0.25416204,  0.02639096, -0.15869278,\n",
      "          -0.17691351, -0.18187381,  0.02344535,  0.07960067,\n",
      "           0.09097182, -0.05249939, -0.05736518, -0.17597324]]],\n",
      "\n",
      "\n",
      "       [[[ 0.24911751,  0.16263413, -0.2612211 ,  0.17636439,\n",
      "          -0.05895835, -0.11139686, -0.17085399,  0.08696651,\n",
      "          -0.06234757, -0.11008604, -0.06621098,  0.13904954,\n",
      "          -0.11906273, -0.15719391,  0.17204252,  0.04321454],\n",
      "         [-0.14196685,  0.03036411, -0.11675999,  0.04870843,\n",
      "          -0.0114282 ,  0.13796514, -0.27385128,  0.23680606,\n",
      "           0.07916813, -0.07683091, -0.14114784, -0.11126698,\n",
      "          -0.17998776,  0.08651467,  0.12261181, -0.20619237],\n",
      "         [-0.22975536,  0.04305881, -0.21737394,  0.17368338,\n",
      "          -0.07921582,  0.1286534 ,  0.12456547, -0.00154582,\n",
      "           0.08842021, -0.0060533 , -0.02237519,  0.07454681,\n",
      "           0.10959461,  0.08374444,  0.19090785,  0.19249652]],\n",
      "\n",
      "        [[ 0.14605284, -0.09005452, -0.18849018,  0.20667146,\n",
      "          -0.21264142,  0.01145978, -0.04213556, -0.07035504,\n",
      "          -0.02698999, -0.16579914, -0.14454742,  0.02026226,\n",
      "           0.16326499, -0.19766457, -0.23538302, -0.03669612],\n",
      "         [-0.06679961, -0.02315962,  0.12720451, -0.08122355,\n",
      "          -0.21716344, -0.21718656,  0.07770888,  0.06156615,\n",
      "          -0.21550855,  0.1578381 ,  0.024174  , -0.15686055,\n",
      "          -0.06706225, -0.22631316, -0.17002727, -0.06095234],\n",
      "         [ 0.03400987, -0.07502685, -0.09164315, -0.2626109 ,\n",
      "          -0.22371474, -0.04688312,  0.06088391, -0.17603461,\n",
      "          -0.18602926, -0.1278032 , -0.1969397 ,  0.12268455,\n",
      "          -0.22319566, -0.01285187, -0.0569414 ,  0.05053926]]]],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(16,), dtype=float32, numpy=\n",
      "array([ 0.00506828, -0.01766999, -0.00173465, -0.00726146, -0.00313756,\n",
      "        0.0042079 ,  0.00197241, -0.00568792, -0.00856153, -0.01763003,\n",
      "        0.00214808,  0.00994191, -0.00088604, -0.00868265, -0.00841592,\n",
      "       -0.01153888], dtype=float32)>, <tf.Tensor: shape=(2, 2, 16, 32), dtype=float32, numpy=\n",
      "array([[[[-3.10452040e-02, -1.65771231e-01,  3.16918902e-02, ...,\n",
      "          -7.12889880e-02, -8.94017294e-02, -1.42346263e-01],\n",
      "         [-1.19032450e-01,  4.47049886e-02, -8.24757740e-02, ...,\n",
      "           7.67486542e-02,  7.51885474e-02, -1.44583121e-01],\n",
      "         [-1.51620805e-01,  1.45832464e-01, -1.60689965e-01, ...,\n",
      "          -1.06769256e-01, -1.55348122e-01, -3.24519910e-02],\n",
      "         ...,\n",
      "         [ 2.67042685e-02,  1.45452246e-01, -7.85054490e-02, ...,\n",
      "          -1.27172887e-01,  5.71430400e-02,  1.10772923e-01],\n",
      "         [ 1.16603136e-01,  1.10420674e-01,  1.16662540e-01, ...,\n",
      "          -1.16728926e-02, -1.13432752e-02,  1.25425383e-01],\n",
      "         [ 1.32845819e-01,  1.14687167e-01,  3.61991078e-02, ...,\n",
      "           1.10985227e-01,  3.74843106e-02, -1.09114699e-01]],\n",
      "\n",
      "        [[ 6.32057562e-02,  1.01648055e-01,  1.45610183e-01, ...,\n",
      "           5.94540089e-02,  1.30527467e-01, -3.73115167e-02],\n",
      "         [-4.39288728e-02,  6.93684891e-02,  5.13535552e-03, ...,\n",
      "          -2.37244647e-02, -4.62747589e-02, -1.15209647e-01],\n",
      "         [-1.60751641e-02, -1.68619588e-01, -1.30948424e-01, ...,\n",
      "          -2.95776762e-02, -9.22736749e-02, -7.77369067e-02],\n",
      "         ...,\n",
      "         [ 1.56650040e-02, -1.42056033e-01, -1.43220633e-01, ...,\n",
      "           1.31182164e-01, -5.23986034e-02, -6.93613589e-02],\n",
      "         [-1.51864260e-01, -1.05334036e-01,  1.44618601e-01, ...,\n",
      "          -1.87166687e-02,  8.80819187e-02,  4.69129235e-02],\n",
      "         [-1.63799182e-01, -3.70529853e-02,  1.63326144e-01, ...,\n",
      "           1.34874403e-01, -5.40510826e-02,  5.93302250e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 1.46521721e-02,  4.78443950e-02, -4.44756150e-02, ...,\n",
      "          -1.52754098e-01, -8.64152312e-02,  1.34816483e-01],\n",
      "         [-3.80033851e-02,  6.37701154e-02,  8.10316205e-02, ...,\n",
      "           1.35714352e-01,  1.27098709e-01,  1.27674520e-01],\n",
      "         [ 5.80277331e-02,  1.50085881e-01, -1.50391191e-01, ...,\n",
      "          -5.77366650e-02,  1.49201095e-01,  1.25303920e-02],\n",
      "         ...,\n",
      "         [ 1.89658049e-02,  1.22349888e-01, -1.20363951e-01, ...,\n",
      "          -1.26400753e-03, -1.78779028e-02,  5.91518730e-02],\n",
      "         [-4.09307815e-02, -1.21942244e-01,  1.03601456e-01, ...,\n",
      "           6.07144646e-02, -7.08569810e-02,  1.10473514e-01],\n",
      "         [ 1.49309471e-01,  5.73574156e-02,  1.55254275e-01, ...,\n",
      "           1.24103829e-01,  1.65953100e-01, -1.75370499e-02]],\n",
      "\n",
      "        [[ 3.99121717e-02,  9.20757875e-02,  5.77950617e-03, ...,\n",
      "           2.89317612e-02,  5.14418930e-02,  8.32549036e-02],\n",
      "         [-1.22432426e-01, -1.11464947e-01, -1.49340659e-01, ...,\n",
      "           1.18013695e-01,  2.04385146e-02, -1.38764679e-01],\n",
      "         [-1.05988398e-01, -1.65770486e-01,  2.07457896e-02, ...,\n",
      "           1.01180770e-01, -1.33846954e-01,  2.66025942e-02],\n",
      "         ...,\n",
      "         [-1.92962345e-02, -9.77499187e-02, -1.53561130e-01, ...,\n",
      "          -8.88771787e-02,  1.74473450e-02,  7.92334378e-02],\n",
      "         [ 1.11967579e-01, -1.43672246e-03, -1.23272449e-01, ...,\n",
      "          -8.13836828e-02, -6.24053515e-02,  1.29111260e-01],\n",
      "         [-2.72573725e-05,  8.58750418e-02,  1.08906157e-01, ...,\n",
      "           1.40679792e-01,  1.64371207e-01,  1.41772330e-01]]]],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "array([ 0.00384008, -0.01155538, -0.0006933 ,  0.00673854, -0.01096133,\n",
      "       -0.0088471 ,  0.00222129, -0.00786048, -0.00145132, -0.00271094,\n",
      "       -0.00196854,  0.00315402,  0.00245055, -0.00071932, -0.01904575,\n",
      "        0.00063862, -0.00080155, -0.00786946,  0.00511555,  0.00194241,\n",
      "       -0.00369404,  0.00422722,  0.00710251, -0.00768844, -0.002748  ,\n",
      "        0.01447765, -0.00152291, -0.01068418, -0.0105252 , -0.01136534,\n",
      "       -0.00551673,  0.01161661], dtype=float32)>, <tf.Tensor: shape=(2, 2, 32, 64), dtype=float32, numpy=\n",
      "array([[[[-0.07271314, -0.03661291,  0.06771221, ...,  0.02820135,\n",
      "           0.08004276, -0.123281  ],\n",
      "         [-0.07849746,  0.0133992 ,  0.06437292, ..., -0.11674777,\n",
      "          -0.1027787 ,  0.03650156],\n",
      "         [ 0.03249827,  0.07020041,  0.04978197, ...,  0.02655065,\n",
      "           0.0710303 ,  0.11076007],\n",
      "         ...,\n",
      "         [-0.08608542,  0.02877705,  0.02336797, ...,  0.01229196,\n",
      "           0.094294  ,  0.02263808],\n",
      "         [ 0.09741095,  0.09376924, -0.03647155, ..., -0.11430825,\n",
      "           0.09372401,  0.0121312 ],\n",
      "         [-0.09918702, -0.1008818 ,  0.01846998, ...,  0.05067653,\n",
      "           0.06405233,  0.06169213]],\n",
      "\n",
      "        [[-0.01276078, -0.00855684, -0.12172627, ...,  0.10075283,\n",
      "          -0.10023431,  0.0682529 ],\n",
      "         [ 0.09500603, -0.12037086, -0.08655788, ...,  0.02625727,\n",
      "           0.06180816,  0.03480436],\n",
      "         [-0.01918123,  0.04444182, -0.03021561, ..., -0.02465874,\n",
      "          -0.05561083,  0.04306651],\n",
      "         ...,\n",
      "         [-0.11594206,  0.05607282,  0.0319229 , ...,  0.03579106,\n",
      "           0.0398515 , -0.05655141],\n",
      "         [-0.09322179, -0.10047572,  0.11536609, ..., -0.01162999,\n",
      "           0.04154912,  0.00890454],\n",
      "         [ 0.02911988, -0.056011  , -0.12149202, ...,  0.11408462,\n",
      "           0.01401784, -0.00430269]]],\n",
      "\n",
      "\n",
      "       [[[-0.06478484,  0.06985316,  0.08075906, ...,  0.00203874,\n",
      "           0.07554638,  0.01092036],\n",
      "         [-0.02213486, -0.06865327,  0.10140542, ..., -0.01845092,\n",
      "          -0.00160693, -0.01787191],\n",
      "         [-0.08843042, -0.05752318,  0.02934691, ..., -0.08995344,\n",
      "           0.08215305,  0.0224632 ],\n",
      "         ...,\n",
      "         [ 0.01436698,  0.01062349, -0.04312658, ...,  0.08600149,\n",
      "           0.01863987, -0.09975194],\n",
      "         [-0.07871946,  0.11179826,  0.0041768 , ..., -0.01571105,\n",
      "           0.00530364,  0.08289202],\n",
      "         [-0.09700264, -0.10383042,  0.02022662, ...,  0.1124451 ,\n",
      "           0.02491022, -0.06586932]],\n",
      "\n",
      "        [[ 0.00622154,  0.09901623, -0.08822928, ...,  0.08658978,\n",
      "           0.08149263,  0.03696993],\n",
      "         [-0.11749488,  0.10153038,  0.08500011, ..., -0.09720924,\n",
      "          -0.00847938,  0.03249317],\n",
      "         [-0.00945199, -0.02429453,  0.12276315, ..., -0.07077184,\n",
      "          -0.06586426, -0.07096267],\n",
      "         ...,\n",
      "         [-0.01708458,  0.04639737,  0.08167805, ...,  0.07302684,\n",
      "           0.04484671,  0.06320883],\n",
      "         [ 0.10631239, -0.01595175,  0.08817054, ..., -0.02704013,\n",
      "          -0.01200166,  0.09659184],\n",
      "         [-0.08135176, -0.01370824, -0.09811608, ...,  0.03855305,\n",
      "           0.01823928,  0.07816926]]]], dtype=float32)>, <tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
      "array([-0.00397194,  0.00451474, -0.00249041, -0.00269916, -0.00160834,\n",
      "       -0.00218028, -0.00222172, -0.00962499, -0.00067624, -0.00449081,\n",
      "        0.00274429, -0.01278776, -0.00586638, -0.00982224, -0.00975857,\n",
      "       -0.00604646, -0.01126451, -0.00036704,  0.00263004,  0.00223521,\n",
      "        0.0053073 , -0.01045249,  0.00058555,  0.00123227, -0.00340005,\n",
      "       -0.00378618,  0.00262478, -0.00238003, -0.00510114,  0.00151588,\n",
      "        0.00167065, -0.00909391, -0.01163007,  0.00400092, -0.01129274,\n",
      "        0.00071509, -0.00169822, -0.00553611,  0.00269198, -0.00759072,\n",
      "       -0.00506081, -0.00633425, -0.00551354, -0.00041161, -0.0082903 ,\n",
      "       -0.00425017,  0.00306172, -0.01528898, -0.0011147 , -0.01137576,\n",
      "       -0.00025606, -0.00935275, -0.01109335,  0.00449413,  0.00283181,\n",
      "       -0.00319885,  0.00550977, -0.01102355, -0.00165181,  0.00569618,\n",
      "        0.00193691,  0.00440178,  0.00057233, -0.010843  ], dtype=float32)>, <tf.Tensor: shape=(2304, 500), dtype=float32, numpy=\n",
      "array([[-0.00241214,  0.00818791,  0.03689302, ...,  0.04088719,\n",
      "         0.03003709,  0.01572848],\n",
      "       [-0.00247476, -0.00564375,  0.01539259, ...,  0.00790391,\n",
      "         0.04090362, -0.04161594],\n",
      "       [-0.04472401,  0.02154338, -0.01744824, ...,  0.00182669,\n",
      "         0.03370306,  0.02800969],\n",
      "       ...,\n",
      "       [ 0.03911429,  0.03027688, -0.02568748, ...,  0.0039485 ,\n",
      "        -0.01704783,  0.04858692],\n",
      "       [ 0.00429521,  0.01824591, -0.02290563, ...,  0.03481765,\n",
      "        -0.03533815,  0.00845069],\n",
      "       [ 0.03761672,  0.02333466, -0.02384497, ...,  0.01901428,\n",
      "         0.01034421, -0.02450879]], dtype=float32)>, <tf.Tensor: shape=(500,), dtype=float32, numpy=\n",
      "array([-3.22662224e-03, -2.25899601e-03, -5.51996054e-03,  3.85786756e-03,\n",
      "       -3.60780163e-04,  6.47342473e-04, -5.84027497e-04,  5.63052250e-03,\n",
      "        3.91431199e-03, -1.14023974e-02, -7.49444938e-04,  7.14649912e-04,\n",
      "       -3.75104626e-03,  3.53796035e-03, -4.91104880e-03,  5.18028671e-03,\n",
      "       -1.03281171e-03,  6.86103757e-03,  1.09486254e-02, -1.96604081e-03,\n",
      "       -1.51534961e-03,  6.26409519e-03, -5.95899438e-03, -2.34855060e-03,\n",
      "       -4.57328279e-03, -5.03575895e-03, -2.85449182e-03, -8.52683187e-03,\n",
      "       -7.21193524e-03, -4.46098484e-03, -7.09705520e-03,  4.94992081e-03,\n",
      "       -5.99923264e-03,  3.07547068e-03,  3.76867806e-03,  3.50513402e-03,\n",
      "       -4.01487062e-03,  1.16416509e-03, -5.89058502e-03, -1.80280523e-03,\n",
      "        2.04257201e-03,  1.89398753e-03, -2.87587591e-03, -2.80972291e-03,\n",
      "        1.32155174e-03, -7.21767731e-03, -3.80562479e-03, -6.43106829e-03,\n",
      "       -5.11966739e-03,  1.35322614e-03,  7.01939873e-03, -4.11547022e-03,\n",
      "       -1.06662568e-02,  4.92664520e-03, -7.58393202e-03,  7.00371945e-03,\n",
      "       -8.84050597e-03, -5.53765241e-03,  6.01221016e-03, -4.62867739e-03,\n",
      "       -3.88400885e-03, -5.38281631e-03, -5.52494358e-03, -5.53016458e-03,\n",
      "       -2.38503283e-03, -6.55894983e-04,  4.99670627e-03,  7.03030592e-03,\n",
      "        3.40773631e-03,  7.69715384e-03,  1.77352643e-03,  6.02178089e-03,\n",
      "        3.34891002e-03, -5.24880039e-03, -1.06692594e-02, -4.80448129e-03,\n",
      "       -6.84927450e-03,  2.60347547e-03, -5.04377158e-03, -2.95082456e-03,\n",
      "        5.38897794e-03, -3.22401780e-03,  8.79411178e-04,  2.07558810e-03,\n",
      "       -5.40502369e-03, -4.54461155e-03, -5.52571099e-03, -9.89972730e-04,\n",
      "       -5.74968988e-03, -5.27413236e-03, -4.39170655e-03, -4.16727178e-03,\n",
      "       -8.59085284e-03,  3.88048775e-03,  5.80434315e-03, -4.08162363e-03,\n",
      "       -1.04577933e-03, -5.25728846e-03,  5.88921225e-03,  6.52908930e-04,\n",
      "       -5.53810457e-03, -6.68063876e-04, -4.28063516e-03, -4.04963968e-03,\n",
      "       -4.95009357e-03, -3.48598999e-03, -5.53280115e-03, -2.89525650e-03,\n",
      "       -5.07409079e-03,  3.35930567e-03, -6.70569902e-03, -5.53585449e-03,\n",
      "       -3.90526047e-03,  7.23376230e-04, -4.00167331e-03,  9.03764332e-04,\n",
      "        1.10600621e-03,  2.07405514e-03, -5.53080067e-03, -3.07986047e-03,\n",
      "        9.38342186e-04, -1.53541216e-03, -3.20097053e-04, -3.57933529e-03,\n",
      "       -2.36076885e-04, -1.22140441e-03, -8.79810599e-04, -3.18456022e-03,\n",
      "        6.31116272e-04,  1.91607734e-03, -8.52338318e-03, -2.09626276e-03,\n",
      "        5.66612743e-03,  2.20535928e-03, -4.27383324e-03, -2.20146379e-03,\n",
      "        6.14795787e-03,  6.97815511e-03,  2.10565189e-03,  8.40888417e-04,\n",
      "        2.39035673e-03, -5.73310489e-03, -4.95025283e-03, -5.63960010e-03,\n",
      "       -4.05383529e-03, -3.72118549e-03,  1.61730789e-03, -4.49262188e-06,\n",
      "        3.45786824e-03, -9.24557040e-04,  7.91056454e-03, -5.96416090e-03,\n",
      "       -4.38530883e-03, -5.53551316e-03, -4.63856431e-03,  7.78949773e-03,\n",
      "       -4.54963977e-03,  8.76547769e-04,  6.31598569e-03, -1.93245395e-03,\n",
      "       -2.06211815e-03, -5.16549591e-03, -6.05089543e-03, -6.80959830e-03,\n",
      "       -7.51036173e-03,  1.93933665e-03,  4.53523826e-03, -5.42445667e-03,\n",
      "        9.72927664e-04, -7.94456713e-03,  8.78040446e-04,  3.05488682e-03,\n",
      "       -7.23326579e-03,  2.44495785e-03, -3.56996106e-03,  2.38286820e-03,\n",
      "        6.69044815e-03, -5.54368785e-03, -7.65501987e-03,  3.53407301e-03,\n",
      "        3.00505111e-04, -5.54186990e-03,  1.54661038e-03,  7.63304206e-03,\n",
      "        5.03759552e-03, -3.77948303e-03, -3.51930480e-03, -4.52452619e-03,\n",
      "       -3.65478895e-03, -7.99890235e-03, -5.28104464e-03,  5.86792268e-03,\n",
      "        5.79213537e-03, -4.54658293e-04,  5.65520488e-03, -7.80911930e-03,\n",
      "        4.93570464e-03, -8.13497230e-03, -8.25630687e-03, -5.94296027e-03,\n",
      "        1.21270856e-02, -6.16340432e-03, -9.69710108e-03, -4.38855542e-03,\n",
      "       -9.03216284e-03, -5.52007789e-03, -3.72768706e-03,  9.77700204e-03,\n",
      "       -3.87369189e-03, -1.48087437e-03, -5.58448117e-03, -7.44657917e-03,\n",
      "        1.12925528e-03, -5.46062272e-03, -5.52523928e-03, -3.68508627e-03,\n",
      "        3.23154707e-03, -7.14908214e-03, -5.53831784e-03, -4.22405172e-03,\n",
      "       -6.81099575e-03, -6.26098551e-03, -6.31918432e-03,  9.66819469e-04,\n",
      "        1.91716035e-03, -6.72416529e-03,  5.96144795e-03, -6.72609080e-03,\n",
      "       -3.78717366e-03,  2.61100847e-03, -1.36096065e-03, -5.33877546e-03,\n",
      "       -5.82149765e-03, -3.75446491e-03, -3.89848137e-03, -5.22281090e-03,\n",
      "       -6.04925677e-04, -7.30815064e-03, -4.82486095e-03, -1.85790181e-03,\n",
      "       -5.10872109e-03, -8.74435995e-03,  6.60545332e-03, -8.51673074e-03,\n",
      "        4.42316895e-03, -5.84490038e-03, -1.12189874e-02, -5.56187704e-03,\n",
      "        7.61159835e-03, -6.05153991e-03,  5.12133632e-03, -3.38028604e-03,\n",
      "        5.90545265e-03, -3.67194554e-03, -5.40535199e-03, -2.67771096e-03,\n",
      "       -5.52781438e-03, -4.86271456e-03, -8.26532114e-03, -5.01458673e-03,\n",
      "       -5.64129930e-03, -1.55453559e-03, -6.20743213e-03, -3.35579040e-03,\n",
      "       -6.18393021e-03, -8.00194126e-03, -1.00982178e-03,  8.03193077e-03,\n",
      "       -2.43527256e-03, -4.70366003e-03,  5.44611318e-03, -8.16121697e-03,\n",
      "       -5.55319572e-03, -5.63530810e-03, -7.24348845e-03, -4.54681600e-03,\n",
      "       -4.75837849e-03, -5.81039023e-03,  8.37993575e-04,  5.24797710e-03,\n",
      "       -1.14026235e-03, -4.10206337e-03, -5.10044862e-03,  4.55794996e-03,\n",
      "       -5.69381565e-03, -6.48221187e-03, -4.45427792e-03,  2.13180785e-03,\n",
      "       -8.03842768e-03,  3.33577627e-03, -5.74881025e-03, -7.58587988e-03,\n",
      "       -8.25217925e-03,  9.41465434e-04, -9.76445270e-04, -2.25519203e-03,\n",
      "       -4.95589012e-03, -3.53051396e-03, -6.08631410e-03, -4.67545958e-03,\n",
      "       -7.59787858e-03, -5.96752157e-03,  1.76231016e-03, -5.36340149e-03,\n",
      "       -3.47681693e-04, -1.58317765e-04, -5.52943302e-03, -6.82932464e-03,\n",
      "        2.39231414e-03, -1.07517641e-03,  4.42942511e-03, -4.18686215e-03,\n",
      "        2.15961225e-03,  9.59436467e-04,  9.45350900e-03, -7.64487544e-03,\n",
      "       -3.87308933e-03,  5.15665486e-03, -8.33353773e-03,  4.71373182e-03,\n",
      "       -3.49258073e-03, -5.55194914e-03,  6.85774302e-03, -6.73487596e-03,\n",
      "        2.18074885e-03, -1.06912968e-03,  2.31453057e-04,  5.45546925e-03,\n",
      "       -8.92650615e-03, -5.60575025e-03, -5.52501436e-03,  7.17996573e-03,\n",
      "       -2.82661687e-03,  4.55244491e-03,  4.38956637e-03, -7.69142294e-03,\n",
      "       -3.28586646e-03, -4.17812588e-03,  1.79477921e-03,  5.99808479e-03,\n",
      "       -3.55678424e-03,  3.85162001e-03, -5.54270251e-03, -8.33896548e-03,\n",
      "       -5.49682137e-03, -7.70247728e-03, -7.91149773e-03,  2.20667243e-05,\n",
      "       -4.77020722e-03, -1.67480973e-03, -6.96580065e-03, -8.63718893e-03,\n",
      "        5.27413469e-03, -7.02802371e-03,  5.32470318e-03, -5.98991243e-03,\n",
      "        1.24250923e-03,  4.58075944e-03,  2.85036815e-03, -5.52979065e-03,\n",
      "        1.69601990e-03, -1.84060237e-03, -2.81555206e-03, -1.31543260e-03,\n",
      "        5.43523114e-03,  2.21736715e-04, -6.07462507e-03, -2.35203118e-03,\n",
      "        6.63879095e-03,  1.12655631e-03, -5.37435710e-03, -4.90407925e-03,\n",
      "        1.22340175e-03, -5.17472858e-03, -1.23346527e-03,  1.39299445e-04,\n",
      "        4.59528388e-03, -6.60105888e-03, -6.24206383e-03,  5.63468970e-03,\n",
      "        1.57536287e-03,  4.70839441e-03, -5.55841113e-03,  1.29563059e-03,\n",
      "        1.50020386e-03, -3.32311331e-03,  6.59900066e-03,  4.77883173e-03,\n",
      "       -4.94608376e-03,  1.09238504e-03,  3.36963427e-03, -5.15798340e-04,\n",
      "        1.74519897e-03, -6.34621736e-03, -3.56874405e-03,  6.75420091e-03,\n",
      "       -4.80356131e-04,  5.75907202e-03, -2.24849046e-03,  2.43718433e-03,\n",
      "       -7.69565115e-04,  6.02505496e-03, -7.75186950e-03,  6.33560028e-03,\n",
      "        5.48187923e-03,  3.60879791e-03,  2.64881249e-03,  6.25068508e-03,\n",
      "       -5.27481921e-03, -7.67346285e-03, -3.52444127e-03, -8.88178684e-03,\n",
      "        4.82928287e-03, -5.14358049e-03, -4.98831365e-03,  5.06302575e-03,\n",
      "       -4.26517753e-03, -5.64062130e-03, -7.99508486e-03, -4.75715846e-03,\n",
      "        5.54394908e-03,  5.65482304e-03, -4.17732866e-03,  1.02790701e-03,\n",
      "       -8.32639262e-03, -6.80117263e-03, -2.94964737e-03, -8.31876998e-04,\n",
      "       -4.81192442e-03, -6.28215587e-03,  1.48669409e-04, -2.60407804e-03,\n",
      "       -6.53736992e-03,  2.12053023e-03, -4.99674678e-03, -4.36749076e-03,\n",
      "        6.76238851e-04, -5.35098510e-03,  4.77626873e-03,  9.83927981e-04,\n",
      "        7.85215292e-03, -5.02501568e-03, -5.52232470e-03,  6.41120318e-03,\n",
      "       -5.53466007e-03,  4.52360138e-03, -8.32519867e-03, -4.47951350e-03,\n",
      "        4.80696652e-03, -2.06083758e-03,  3.61335906e-03,  4.86609852e-03,\n",
      "        2.14604707e-03, -8.17465782e-03,  6.90040470e-04, -9.02028382e-03,\n",
      "        6.33477978e-03, -5.04367426e-03, -3.57426447e-03, -9.21013020e-03,\n",
      "       -5.45945670e-03,  7.65487610e-04,  4.44565155e-03,  1.53158663e-03,\n",
      "       -1.21482043e-03,  2.97319959e-03,  1.30283518e-03, -1.01296455e-02,\n",
      "       -4.70706727e-03, -3.40489135e-03, -6.80084806e-03,  7.71822082e-03,\n",
      "       -7.80088222e-03, -5.53361978e-03, -4.94121201e-03, -4.62010037e-03,\n",
      "       -3.59159196e-03, -6.91542309e-03,  6.89604320e-04,  4.20639478e-03,\n",
      "        2.28066603e-03,  5.46910986e-03,  2.46238057e-03,  5.24349371e-03,\n",
      "       -5.78420702e-03,  9.99813899e-03,  2.33784388e-03, -7.77098630e-03,\n",
      "        1.64144405e-03,  2.77463638e-04,  1.66698010e-03, -3.38720251e-03,\n",
      "       -2.31958274e-03,  4.54820460e-03, -8.75390950e-04, -3.31418263e-03,\n",
      "       -6.99611660e-03, -4.54719318e-03, -7.29710143e-03,  8.13678186e-03],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(500, 2), dtype=float32, numpy=\n",
      "array([[ 3.28662209e-02, -4.50908206e-02],\n",
      "       [ 5.76195633e-03,  2.96205115e-02],\n",
      "       [ 9.15167704e-02,  5.52086718e-02],\n",
      "       [ 3.51522341e-02, -6.52144775e-02],\n",
      "       [-9.85767692e-03,  6.48633763e-02],\n",
      "       [-1.00011013e-01, -8.44400674e-02],\n",
      "       [-9.08016600e-03, -4.07395475e-02],\n",
      "       [ 9.93419513e-02, -1.10091254e-01],\n",
      "       [ 9.35492069e-02,  6.48424029e-02],\n",
      "       [ 6.20445050e-02,  1.01567477e-01],\n",
      "       [ 6.76024109e-02,  6.77661523e-02],\n",
      "       [ 4.50913943e-02,  8.70554149e-02],\n",
      "       [-1.25078503e-02, -1.95813347e-02],\n",
      "       [ 7.76926577e-02,  4.61987294e-02],\n",
      "       [-7.01643080e-02, -7.33794868e-02],\n",
      "       [ 5.51986322e-02, -4.65050340e-02],\n",
      "       [ 8.35026726e-02, -7.43663460e-02],\n",
      "       [ 5.84953576e-02, -6.93290979e-02],\n",
      "       [-3.22329924e-02, -8.40750933e-02],\n",
      "       [ 7.04995617e-02,  1.29164793e-02],\n",
      "       [-1.56642944e-02, -4.04921314e-03],\n",
      "       [ 6.00541271e-02,  2.70678382e-03],\n",
      "       [-9.52773988e-02, -9.87723917e-02],\n",
      "       [ 2.04939954e-02, -1.12793688e-02],\n",
      "       [ 7.06340671e-02,  7.34930038e-02],\n",
      "       [-5.92614226e-02,  9.69891399e-02],\n",
      "       [-5.76838963e-02, -6.74870610e-02],\n",
      "       [-3.07062864e-02, -6.77529573e-02],\n",
      "       [-2.98979059e-02, -2.17008889e-02],\n",
      "       [ 3.68962698e-02,  2.95464545e-02],\n",
      "       [ 8.55430216e-02,  8.32637474e-02],\n",
      "       [ 3.38169336e-02, -3.17473374e-02],\n",
      "       [ 8.33395869e-02, -9.41439718e-02],\n",
      "       [-6.52769655e-02,  1.38223041e-02],\n",
      "       [ 4.34393287e-02, -5.71327768e-02],\n",
      "       [-8.64854455e-02,  6.55464306e-02],\n",
      "       [-3.95420520e-03, -6.99370950e-02],\n",
      "       [ 1.56279076e-02, -5.33899814e-02],\n",
      "       [-4.25262414e-02, -4.63174656e-02],\n",
      "       [-3.07749845e-02,  3.58656570e-02],\n",
      "       [-4.49463613e-02, -1.36018647e-02],\n",
      "       [-1.38546880e-02,  6.17759712e-02],\n",
      "       [-8.45724270e-02,  5.41504063e-02],\n",
      "       [ 3.79226319e-02,  1.42369503e-02],\n",
      "       [-1.91139653e-02,  6.77786618e-02],\n",
      "       [-2.72598136e-02, -5.64622916e-02],\n",
      "       [-6.52994066e-02,  3.49012949e-02],\n",
      "       [ 7.19060302e-02, -7.79714510e-02],\n",
      "       [-6.32096007e-02, -5.78862801e-02],\n",
      "       [-8.37240145e-02,  1.20908385e-02],\n",
      "       [ 1.18447877e-02, -7.85494968e-02],\n",
      "       [-6.82337284e-02, -9.80615541e-02],\n",
      "       [-6.22361479e-03,  5.44295162e-02],\n",
      "       [ 7.36967381e-03, -8.30443278e-02],\n",
      "       [-6.85374578e-03,  9.16769579e-02],\n",
      "       [ 1.05926968e-01, -4.17684056e-02],\n",
      "       [ 7.90591091e-02, -2.27555390e-02],\n",
      "       [-3.96506265e-02,  7.77379125e-02],\n",
      "       [ 1.61284134e-02, -4.17544246e-02],\n",
      "       [ 1.55009413e-02, -7.50894770e-02],\n",
      "       [ 7.99152553e-02,  2.31649987e-02],\n",
      "       [ 1.31828710e-02,  7.87228420e-02],\n",
      "       [-9.05146971e-02,  9.48688295e-03],\n",
      "       [ 5.89391924e-02,  3.34933884e-02],\n",
      "       [ 2.01728800e-03,  4.37553832e-03],\n",
      "       [-8.90329704e-02, -2.27427185e-02],\n",
      "       [ 7.10651949e-02,  4.77726161e-02],\n",
      "       [ 6.67694807e-02, -5.86596988e-02],\n",
      "       [ 2.81785522e-02, -8.10613632e-02],\n",
      "       [ 1.09918460e-01, -5.54708391e-02],\n",
      "       [-6.67478293e-02,  5.84149845e-02],\n",
      "       [ 2.57938486e-02,  5.05608786e-03],\n",
      "       [-8.87330472e-02,  5.64889424e-03],\n",
      "       [ 3.68787684e-02, -5.40827326e-02],\n",
      "       [ 3.16563435e-02,  3.31599824e-02],\n",
      "       [-2.03475151e-02, -6.50794953e-02],\n",
      "       [ 8.27445090e-02, -3.23001780e-02],\n",
      "       [-1.00403868e-01,  7.39862472e-02],\n",
      "       [-3.04014795e-03, -9.36215445e-02],\n",
      "       [ 4.53979447e-02,  4.31790873e-02],\n",
      "       [ 7.66787911e-03, -1.05610423e-01],\n",
      "       [-4.19365130e-02, -6.98804185e-02],\n",
      "       [-6.51414739e-03,  5.88355437e-02],\n",
      "       [ 7.66121298e-02, -7.68747106e-02],\n",
      "       [-8.34229290e-02,  2.68772412e-02],\n",
      "       [ 7.79685825e-02,  7.47345090e-02],\n",
      "       [-7.47574940e-02, -4.70137000e-02],\n",
      "       [-2.89827045e-02,  4.71172631e-02],\n",
      "       [ 5.76492958e-02, -6.77156597e-02],\n",
      "       [-9.61387716e-03,  8.40902105e-02],\n",
      "       [ 6.21922640e-03,  4.67672199e-03],\n",
      "       [ 7.96695799e-02,  7.32422248e-02],\n",
      "       [ 6.32270426e-02,  5.28768301e-02],\n",
      "       [ 2.05918634e-03,  8.51374418e-02],\n",
      "       [ 1.56264231e-02, -9.66313109e-02],\n",
      "       [-6.34760931e-02, -6.14487566e-02],\n",
      "       [-9.65693519e-02,  5.81488796e-02],\n",
      "       [-9.39140171e-02,  5.71689941e-02],\n",
      "       [ 7.84027204e-02,  1.35417022e-02],\n",
      "       [-4.45300639e-02,  6.26011379e-03],\n",
      "       [-7.94020817e-02, -1.71380825e-02],\n",
      "       [ 3.60832503e-03,  4.36991937e-02],\n",
      "       [-3.16631272e-02, -3.65308747e-02],\n",
      "       [ 4.62663695e-02,  1.06985457e-01],\n",
      "       [ 6.98996633e-02,  7.40329102e-02],\n",
      "       [-7.78756216e-02,  5.17116003e-02],\n",
      "       [-4.95694950e-02,  3.17965895e-02],\n",
      "       [-7.30310678e-02, -6.39414787e-02],\n",
      "       [-1.83265470e-03,  9.56795290e-02],\n",
      "       [-7.06400499e-02,  8.65929872e-02],\n",
      "       [-1.14344740e-02,  3.03803440e-02],\n",
      "       [ 2.49890778e-02, -9.41399634e-02],\n",
      "       [-1.48481335e-02, -2.34739091e-02],\n",
      "       [ 2.09036507e-02,  1.02163203e-01],\n",
      "       [-7.73309693e-02,  7.48620555e-02],\n",
      "       [ 1.73228383e-02,  3.81776728e-02],\n",
      "       [-9.47178304e-02,  9.64058656e-03],\n",
      "       [-5.76511398e-02,  7.18655512e-02],\n",
      "       [ 4.07312124e-04,  6.70517236e-02],\n",
      "       [ 8.43088999e-02, -6.04390688e-02],\n",
      "       [ 7.17468793e-03,  9.52629671e-02],\n",
      "       [-4.89430763e-02,  1.00423247e-01],\n",
      "       [ 7.68365711e-02, -7.73476139e-02],\n",
      "       [-8.91297758e-02, -6.49785921e-02],\n",
      "       [ 1.29356077e-02,  3.38413976e-02],\n",
      "       [-9.32754651e-02,  1.01697937e-01],\n",
      "       [-7.19673187e-02,  6.07777908e-02],\n",
      "       [ 8.47031921e-02,  2.19969433e-02],\n",
      "       [ 1.14405025e-02,  8.56701136e-02],\n",
      "       [ 6.45909086e-02, -8.78551304e-02],\n",
      "       [ 2.66626775e-02,  3.58616523e-02],\n",
      "       [ 6.24203458e-02,  6.04579635e-02],\n",
      "       [ 7.97634795e-02, -9.75710340e-03],\n",
      "       [-2.09669191e-02,  9.19852555e-02],\n",
      "       [ 1.33301998e-02,  9.67586264e-02],\n",
      "       [-8.62762630e-02, -9.46161225e-02],\n",
      "       [ 9.72373858e-02, -6.68884441e-02],\n",
      "       [ 9.80591699e-02, -8.56538266e-02],\n",
      "       [-8.63345489e-02, -4.65784594e-02],\n",
      "       [-7.07662404e-02, -4.59490269e-02],\n",
      "       [-1.35455858e-02,  8.19120035e-02],\n",
      "       [-5.10518923e-02,  8.14098418e-02],\n",
      "       [ 1.50519144e-02,  1.24951089e-02],\n",
      "       [-6.98147118e-02, -2.62211263e-02],\n",
      "       [ 3.73257999e-03, -4.42249328e-02],\n",
      "       [-7.90050626e-03, -9.75074843e-02],\n",
      "       [-1.58102438e-02,  7.32648596e-02],\n",
      "       [-4.32455204e-02,  1.67811401e-02],\n",
      "       [-5.00183506e-03, -2.49222741e-02],\n",
      "       [ 4.03094590e-02,  6.19868785e-02],\n",
      "       [ 4.93338890e-02,  9.01715714e-04],\n",
      "       [ 4.48379070e-02, -3.55208926e-02],\n",
      "       [-6.36616424e-02, -8.39879885e-02],\n",
      "       [ 2.21029092e-02, -2.08496768e-03],\n",
      "       [ 9.46332514e-02, -7.53463134e-02],\n",
      "       [ 7.62524381e-02,  1.13752913e-02],\n",
      "       [-3.01704649e-02, -2.35630553e-02],\n",
      "       [-1.05622217e-01, -7.18594790e-02],\n",
      "       [ 2.49180384e-02, -4.54884246e-02],\n",
      "       [ 3.58339213e-02,  9.55036581e-02],\n",
      "       [ 6.63112104e-02, -6.34166524e-02],\n",
      "       [ 2.60938052e-02, -1.83968805e-02],\n",
      "       [ 8.73451531e-02,  9.20558274e-02],\n",
      "       [ 5.54459430e-02,  5.07827736e-02],\n",
      "       [-4.63261083e-02, -6.07256107e-02],\n",
      "       [-3.55159827e-02,  7.29456916e-02],\n",
      "       [ 9.01760161e-02, -2.96303872e-02],\n",
      "       [ 3.71811651e-02,  3.76062132e-02],\n",
      "       [-3.76311205e-02, -5.10474816e-02],\n",
      "       [-2.78444942e-02,  4.86779511e-02],\n",
      "       [-8.07080939e-02, -4.40086834e-02],\n",
      "       [ 8.91193300e-02, -6.40341491e-02],\n",
      "       [-4.54107001e-02, -1.53953014e-02],\n",
      "       [-2.64520608e-02, -8.81435722e-03],\n",
      "       [ 2.35011410e-02, -8.23674873e-02],\n",
      "       [-2.90161539e-02, -4.18488830e-02],\n",
      "       [ 4.91747595e-02, -7.08134994e-02],\n",
      "       [ 3.83224860e-02, -8.05507153e-02],\n",
      "       [-6.65319934e-02,  4.29372154e-02],\n",
      "       [-5.83422594e-02, -7.36920014e-02],\n",
      "       [ 9.34341997e-02,  2.26568766e-02],\n",
      "       [ 1.78683009e-02, -4.19892557e-02],\n",
      "       [-7.20274374e-02,  6.55523613e-02],\n",
      "       [ 4.74976674e-02, -9.72295329e-02],\n",
      "       [ 8.27026647e-03, -9.86176133e-02],\n",
      "       [-8.52196142e-02, -8.29289481e-02],\n",
      "       [ 6.67291954e-02, -3.93988825e-02],\n",
      "       [-1.78485140e-02,  3.39264274e-02],\n",
      "       [-6.71112835e-02, -5.67051247e-02],\n",
      "       [-2.37403866e-02, -8.52059107e-03],\n",
      "       [-1.91112850e-02, -1.07392808e-02],\n",
      "       [-2.70506628e-02, -9.21827257e-02],\n",
      "       [ 1.10097967e-01,  1.05804922e-02],\n",
      "       [ 7.59111624e-03,  3.10520157e-02],\n",
      "       [ 9.85138044e-02, -1.07402585e-01],\n",
      "       [ 7.20773116e-02, -8.37728903e-02],\n",
      "       [ 1.07561596e-01, -1.04777098e-01],\n",
      "       [ 5.74994050e-02, -3.89583558e-02],\n",
      "       [ 6.69426611e-03,  1.94214433e-02],\n",
      "       [ 1.07672038e-02,  7.19547942e-02],\n",
      "       [-6.92592561e-02, -1.05649769e-01],\n",
      "       [-8.23653936e-02, -8.98767114e-02],\n",
      "       [ 5.25775738e-02,  7.06942901e-02],\n",
      "       [-9.70966294e-02,  1.58963483e-02],\n",
      "       [-6.91287545e-03,  5.47344312e-02],\n",
      "       [-5.41067356e-03,  3.09252981e-02],\n",
      "       [ 1.50617855e-02,  9.38843861e-02],\n",
      "       [ 1.06638484e-01, -5.55856936e-02],\n",
      "       [ 1.70327090e-02,  4.03251126e-02],\n",
      "       [-5.76442666e-02, -3.38633056e-03],\n",
      "       [ 5.53226173e-02, -9.35675800e-02],\n",
      "       [ 3.21186148e-02, -2.90493993e-03],\n",
      "       [-5.93591528e-03,  6.04407396e-03],\n",
      "       [-1.31349871e-03,  8.36950690e-02],\n",
      "       [ 9.47534200e-03,  2.28640828e-02],\n",
      "       [-1.90825555e-02,  4.31758575e-02],\n",
      "       [ 3.86666544e-02,  2.10484676e-02],\n",
      "       [ 6.94489926e-02, -5.78029007e-02],\n",
      "       [-1.69399437e-02, -8.98508206e-02],\n",
      "       [-9.15136412e-02, -9.94719192e-02],\n",
      "       [ 5.46103194e-02,  9.38005522e-02],\n",
      "       [-1.30420886e-02, -7.57272616e-02],\n",
      "       [-5.78233190e-02,  3.47495661e-03],\n",
      "       [-3.30284052e-03,  6.48551136e-02],\n",
      "       [-6.95353076e-02, -1.89215075e-02],\n",
      "       [-8.88138339e-02,  5.04273102e-02],\n",
      "       [ 3.45715298e-03, -5.98452352e-02],\n",
      "       [ 6.12522885e-02, -5.80122285e-02],\n",
      "       [-8.37856084e-02,  5.37216961e-02],\n",
      "       [ 4.89361435e-02,  9.37693566e-02],\n",
      "       [-2.14215480e-02, -6.41944930e-02],\n",
      "       [ 8.41022804e-02, -7.34813139e-02],\n",
      "       [-5.74673600e-02, -5.66280894e-02],\n",
      "       [ 9.53733698e-02,  4.08240333e-02],\n",
      "       [ 4.95143421e-02,  4.85093929e-02],\n",
      "       [-3.54471132e-02,  2.98711732e-02],\n",
      "       [ 6.18733726e-02,  8.13466609e-02],\n",
      "       [-4.45624478e-02, -5.85831739e-02],\n",
      "       [-1.34261465e-02,  6.88779131e-02],\n",
      "       [ 8.96927267e-02, -9.67756510e-02],\n",
      "       [ 5.72996102e-02, -3.86048257e-02],\n",
      "       [-1.57146025e-02,  5.87786175e-02],\n",
      "       [ 4.18442972e-02,  6.85877894e-05],\n",
      "       [-2.73000505e-02, -2.20041792e-03],\n",
      "       [-8.03601891e-02,  4.36453894e-02],\n",
      "       [-3.22343558e-02,  2.73863729e-02],\n",
      "       [-9.28299576e-02, -8.88920054e-02],\n",
      "       [ 5.43669537e-02,  5.77417165e-02],\n",
      "       [-6.39195507e-03, -6.24305382e-02],\n",
      "       [-8.99143368e-02,  4.36427332e-02],\n",
      "       [ 8.09022924e-04, -9.01300535e-02],\n",
      "       [ 8.16622078e-02,  7.56142139e-02],\n",
      "       [ 4.63688262e-02, -1.13374311e-02],\n",
      "       [ 3.79916541e-02,  6.14559352e-02],\n",
      "       [ 2.19784547e-02,  8.47220197e-02],\n",
      "       [ 2.73022596e-02,  3.58724184e-02],\n",
      "       [ 3.68599594e-02, -9.11454409e-02],\n",
      "       [-9.31019560e-02, -2.61885226e-02],\n",
      "       [ 2.65315156e-02, -7.83278495e-02],\n",
      "       [ 8.28060508e-02,  8.59852061e-02],\n",
      "       [-7.14754462e-02, -6.85395747e-02],\n",
      "       [-2.31066402e-02,  1.99106475e-03],\n",
      "       [-2.73418892e-02, -2.88233384e-02],\n",
      "       [ 9.21080187e-02, -2.06352007e-02],\n",
      "       [-7.46158212e-02, -2.73002982e-02],\n",
      "       [ 1.35604560e-03, -1.86490323e-02],\n",
      "       [-6.28093630e-02, -3.09405364e-02],\n",
      "       [ 4.05918323e-02, -9.18499380e-02],\n",
      "       [ 2.44234316e-02,  3.42623517e-02],\n",
      "       [-2.39018388e-02,  4.50957455e-02],\n",
      "       [ 1.10245921e-01,  2.61999704e-02],\n",
      "       [-3.47666033e-02,  4.76813428e-02],\n",
      "       [-2.42386535e-02,  5.86136729e-02],\n",
      "       [-3.27894501e-02, -9.88282729e-03],\n",
      "       [ 7.91265294e-02,  7.58634806e-02],\n",
      "       [-6.05334667e-03,  4.79775555e-02],\n",
      "       [-2.72205118e-02, -4.07214984e-02],\n",
      "       [-8.63938108e-02,  7.58276731e-02],\n",
      "       [-3.94930504e-02,  2.84738978e-03],\n",
      "       [ 6.41400889e-02, -1.90887542e-03],\n",
      "       [-3.62911634e-03,  1.89468190e-02],\n",
      "       [-6.13088347e-02,  7.17629269e-02],\n",
      "       [ 1.04537457e-02, -9.46898684e-02],\n",
      "       [-2.44669747e-02, -8.69509652e-02],\n",
      "       [ 9.77953151e-02, -2.75964215e-02],\n",
      "       [ 1.13829887e-02,  5.84857985e-02],\n",
      "       [-4.92053069e-02,  9.17521119e-02],\n",
      "       [ 4.06824276e-02,  9.12682563e-02],\n",
      "       [ 6.20400943e-02,  6.93703592e-02],\n",
      "       [-3.71181853e-02,  7.46579170e-02],\n",
      "       [-5.21038622e-02,  2.23982967e-02],\n",
      "       [-6.77355975e-02,  4.88627590e-02],\n",
      "       [-3.19037847e-02, -4.58498411e-02],\n",
      "       [ 9.24710557e-03,  6.83453009e-02],\n",
      "       [-2.91596688e-02, -1.00181773e-02],\n",
      "       [-3.90979275e-02, -5.18897511e-02],\n",
      "       [-6.63422942e-02, -2.95962095e-02],\n",
      "       [-1.54635925e-02,  1.89127657e-03],\n",
      "       [ 7.62963966e-02, -2.30806917e-02],\n",
      "       [ 8.71648416e-02,  8.58190656e-02],\n",
      "       [ 7.83848483e-03,  9.04442966e-02],\n",
      "       [-1.96014252e-02, -8.36354271e-02],\n",
      "       [ 6.54324368e-02,  9.88233984e-02],\n",
      "       [ 8.96725506e-02,  4.21882421e-02],\n",
      "       [-1.28117157e-03,  4.64465916e-02],\n",
      "       [-9.06717405e-02,  5.13162911e-02],\n",
      "       [ 3.89027633e-02,  9.65595059e-03],\n",
      "       [-1.63192041e-02, -9.06142173e-04],\n",
      "       [ 1.13910101e-02,  6.29818439e-02],\n",
      "       [ 8.45495705e-03, -2.53863391e-02],\n",
      "       [-4.78157401e-02, -6.25052601e-02],\n",
      "       [-9.28882658e-02,  5.73651772e-03],\n",
      "       [-9.78161097e-02, -4.69229892e-02],\n",
      "       [-9.00198370e-02,  4.83490750e-02],\n",
      "       [ 9.99962613e-02,  4.90607545e-02],\n",
      "       [ 3.21258381e-02,  5.53516019e-03],\n",
      "       [ 2.17959136e-02, -9.03484412e-03],\n",
      "       [-2.54317876e-02, -7.15704560e-02],\n",
      "       [-2.87141688e-02,  4.10129391e-02],\n",
      "       [ 1.29848234e-02, -2.73004379e-02],\n",
      "       [ 4.70136106e-02,  6.71073347e-02],\n",
      "       [ 7.07744882e-02,  4.84566092e-02],\n",
      "       [-5.32414615e-02, -8.99744853e-02],\n",
      "       [-5.64580597e-02, -9.48803350e-02],\n",
      "       [-5.08878455e-02,  9.50699076e-02],\n",
      "       [ 5.63885868e-02,  7.31867924e-02],\n",
      "       [-1.02742435e-02,  7.09663779e-02],\n",
      "       [ 8.51412788e-02, -7.38252327e-02],\n",
      "       [ 3.53952721e-02,  3.48821543e-02],\n",
      "       [-8.69751424e-02, -7.54496381e-02],\n",
      "       [ 1.63919870e-02, -3.52017134e-02],\n",
      "       [ 7.00974539e-02, -5.13488799e-02],\n",
      "       [-8.29522759e-02, -5.56875840e-02],\n",
      "       [ 2.91849039e-02, -7.80633464e-02],\n",
      "       [ 6.95608780e-02, -6.44030795e-02],\n",
      "       [ 7.41546154e-02,  4.00834531e-02],\n",
      "       [ 3.61738838e-02,  8.08124617e-02],\n",
      "       [ 3.74977514e-02,  2.59691179e-02],\n",
      "       [ 1.60792172e-02, -6.15320094e-02],\n",
      "       [ 4.42571864e-02, -5.89588955e-02],\n",
      "       [-2.60037258e-02, -2.08966602e-02],\n",
      "       [-4.54131402e-02, -9.44285095e-02],\n",
      "       [ 9.04278457e-02, -7.44920820e-02],\n",
      "       [ 4.11932468e-02,  3.52178253e-02],\n",
      "       [-9.08432454e-02, -5.26806712e-02],\n",
      "       [ 2.60206480e-02, -1.46904001e-02],\n",
      "       [-9.15809795e-02, -1.78694688e-02],\n",
      "       [ 2.08632182e-02,  6.84886053e-02],\n",
      "       [ 1.37655223e-02,  4.09617908e-02],\n",
      "       [ 2.95768101e-02,  3.99459228e-02],\n",
      "       [ 2.88883001e-02, -8.61628652e-02],\n",
      "       [ 2.60404684e-02,  4.42620032e-02],\n",
      "       [ 5.18842004e-02,  2.00889837e-02],\n",
      "       [ 8.03822745e-03,  1.55883245e-02],\n",
      "       [ 3.42425220e-02, -8.34031180e-02],\n",
      "       [-2.29978468e-02, -4.68561649e-02],\n",
      "       [-6.02689013e-02,  1.36767924e-02],\n",
      "       [ 3.70376259e-02, -3.48755904e-02],\n",
      "       [-5.61484620e-02,  2.39165928e-02],\n",
      "       [ 2.92109698e-02,  2.77229641e-02],\n",
      "       [-6.08462244e-02,  9.97813717e-02],\n",
      "       [-3.98141965e-02,  4.85311002e-02],\n",
      "       [ 1.21264756e-02,  7.34274555e-03],\n",
      "       [-9.11950916e-02, -3.76926828e-03],\n",
      "       [ 3.49930003e-02, -5.22237495e-02],\n",
      "       [-8.09855387e-02,  3.33361030e-02],\n",
      "       [-2.97721196e-02, -7.00512230e-02],\n",
      "       [-4.70751226e-02, -4.80964258e-02],\n",
      "       [ 1.01272583e-01,  3.32126543e-02],\n",
      "       [-4.60005412e-03,  1.93105210e-02],\n",
      "       [-5.58832511e-02, -3.89947295e-02],\n",
      "       [ 6.28577638e-03, -1.34025468e-02],\n",
      "       [-4.26014513e-02, -7.14898203e-03],\n",
      "       [-1.25736613e-02, -8.84574205e-02],\n",
      "       [ 6.32934943e-02, -6.45454079e-02],\n",
      "       [-4.58778953e-03,  3.74183282e-02],\n",
      "       [-7.31789023e-02, -5.23361079e-02],\n",
      "       [ 2.82851849e-02,  4.24581803e-02],\n",
      "       [-4.25650291e-02,  2.39944942e-02],\n",
      "       [ 9.77667794e-02, -2.39874218e-02],\n",
      "       [-3.25563289e-02,  1.42893316e-02],\n",
      "       [ 8.33948106e-02, -3.65516618e-02],\n",
      "       [ 4.27097678e-02, -6.56756088e-02],\n",
      "       [-7.52894357e-02,  2.72646863e-02],\n",
      "       [ 3.83176142e-03,  1.05831876e-01],\n",
      "       [ 3.27545479e-02,  8.57406929e-02],\n",
      "       [ 4.76930849e-02, -1.95027739e-02],\n",
      "       [ 7.68461898e-02,  5.33833988e-02],\n",
      "       [ 3.71802859e-02,  6.30964935e-02],\n",
      "       [ 1.38568813e-02,  8.40554908e-02],\n",
      "       [ 6.70969710e-02, -7.17747584e-02],\n",
      "       [-8.07257146e-02,  3.97861823e-02],\n",
      "       [-7.54173333e-03,  6.84535950e-02],\n",
      "       [ 5.31893261e-02,  8.34302753e-02],\n",
      "       [ 3.60714048e-02, -1.04095452e-02],\n",
      "       [ 1.04845069e-01, -2.27206033e-02],\n",
      "       [-7.06305951e-02, -8.59875884e-03],\n",
      "       [ 7.03210756e-02, -9.74824280e-02],\n",
      "       [-4.24102023e-02, -3.87406126e-02],\n",
      "       [ 1.82595272e-02,  7.89539889e-02],\n",
      "       [-6.18237182e-02, -3.76319624e-02],\n",
      "       [-1.89619064e-02, -9.55128744e-02],\n",
      "       [ 1.00097777e-02,  6.15870580e-02],\n",
      "       [ 7.49784559e-02,  4.45855744e-02],\n",
      "       [ 7.02410415e-02,  2.27929410e-02],\n",
      "       [ 1.06984891e-01,  5.31190597e-02],\n",
      "       [-2.60991082e-02,  4.81698215e-02],\n",
      "       [ 9.73586272e-03, -5.03632985e-02],\n",
      "       [-6.94993585e-02, -5.99769726e-02],\n",
      "       [ 6.30793199e-02,  6.12391159e-02],\n",
      "       [ 3.38018760e-02, -8.43989402e-02],\n",
      "       [-8.73394758e-02, -3.60816382e-02],\n",
      "       [ 2.94277724e-02, -8.27313289e-02],\n",
      "       [ 3.76051441e-02,  2.36660652e-02],\n",
      "       [-8.86030644e-02, -5.00013344e-02],\n",
      "       [-2.12688912e-02, -1.01951733e-01],\n",
      "       [-3.45322583e-03,  9.83407497e-02],\n",
      "       [-7.02183992e-02,  9.41801593e-02],\n",
      "       [ 9.70941707e-02,  9.26837400e-02],\n",
      "       [ 9.83607471e-02,  1.89552531e-02],\n",
      "       [-3.54852267e-02, -8.82816613e-02],\n",
      "       [ 8.96983370e-02, -5.97509816e-02],\n",
      "       [-1.83404097e-03,  5.48576303e-02],\n",
      "       [-1.46637959e-02, -7.76355416e-02],\n",
      "       [-8.26724470e-02, -3.81025136e-03],\n",
      "       [-1.22862784e-02, -1.47631140e-02],\n",
      "       [-2.40243301e-02,  4.77843732e-02],\n",
      "       [-4.71972115e-02,  1.17073057e-03],\n",
      "       [-6.99408352e-02,  4.52680551e-02],\n",
      "       [ 7.33205229e-02,  8.97923857e-02],\n",
      "       [-6.75811693e-02,  7.10632131e-02],\n",
      "       [ 5.91687970e-02, -7.87651762e-02],\n",
      "       [-1.68538056e-02, -9.26442370e-02],\n",
      "       [-2.32830793e-02,  8.82764906e-02],\n",
      "       [-4.35388349e-02, -1.81441251e-02],\n",
      "       [ 5.68142198e-02, -4.71922830e-02],\n",
      "       [-4.42917012e-02, -1.29320407e-02],\n",
      "       [ 8.80137011e-02, -4.91512492e-02],\n",
      "       [-2.37595066e-02, -7.63244554e-02],\n",
      "       [-4.88837808e-02, -3.13515067e-02],\n",
      "       [-2.84234174e-02, -8.37395489e-02],\n",
      "       [-3.26427296e-02, -4.15355489e-02],\n",
      "       [-4.49911878e-02, -7.96049982e-02],\n",
      "       [ 1.03214279e-01, -8.90996959e-03],\n",
      "       [-6.80581927e-02, -2.80304905e-02],\n",
      "       [ 2.96533629e-02, -1.03228480e-01],\n",
      "       [-3.20818052e-02,  8.89697894e-02],\n",
      "       [-3.52774151e-02, -1.28440349e-03],\n",
      "       [ 1.97707433e-02, -1.02170140e-01],\n",
      "       [-5.65386713e-02, -4.38044034e-02],\n",
      "       [ 5.20802289e-02, -6.35708496e-02],\n",
      "       [ 4.43698019e-02, -9.57808495e-02],\n",
      "       [-1.56873371e-02,  7.81858638e-02],\n",
      "       [ 5.97740561e-02,  6.90767318e-02],\n",
      "       [-7.81894289e-03,  9.43887457e-02],\n",
      "       [ 6.30274490e-02,  2.51895525e-02],\n",
      "       [ 1.04452431e-01,  5.77208176e-02],\n",
      "       [-5.18100113e-02, -7.94337913e-02],\n",
      "       [-5.73590100e-02,  5.68591878e-02],\n",
      "       [-9.05489326e-02,  9.12685096e-02],\n",
      "       [-4.18603756e-02, -2.97114607e-02],\n",
      "       [-5.74912429e-02, -5.09921554e-03],\n",
      "       [ 1.01540893e-01, -5.33901975e-02],\n",
      "       [-7.29443207e-02,  8.93865991e-03],\n",
      "       [ 4.44837064e-02, -5.97498678e-02],\n",
      "       [-1.00269333e-01,  8.11666474e-02],\n",
      "       [-5.79844266e-02, -4.48267199e-02],\n",
      "       [ 7.30979368e-02,  3.30464318e-02],\n",
      "       [ 4.44927774e-02,  7.52955303e-02],\n",
      "       [ 2.53846496e-02, -7.00477138e-02],\n",
      "       [ 2.20606141e-02,  4.52528819e-02],\n",
      "       [ 9.29393172e-02,  1.55801454e-03],\n",
      "       [-1.58815928e-05,  6.06233701e-02],\n",
      "       [-8.42291676e-03,  8.61504823e-02],\n",
      "       [ 2.71505658e-02,  6.43045157e-02],\n",
      "       [-8.54809582e-02,  5.33964951e-03],\n",
      "       [ 9.32370350e-02,  2.49796845e-02],\n",
      "       [-7.92373493e-02,  5.40460758e-02],\n",
      "       [-9.48358029e-02, -5.75031489e-02],\n",
      "       [ 8.67498517e-02,  6.83201700e-02],\n",
      "       [-7.55997375e-02, -4.48252521e-02],\n",
      "       [ 6.84362426e-02, -1.01292908e-01],\n",
      "       [-2.05986518e-02,  5.51716462e-02],\n",
      "       [ 3.41973826e-02,  8.83368775e-02],\n",
      "       [ 1.02223717e-01, -1.06338359e-01],\n",
      "       [ 1.04860954e-01,  5.60414195e-02],\n",
      "       [-3.23854573e-02,  2.82388739e-02],\n",
      "       [-2.38476116e-02, -6.12711883e-04],\n",
      "       [-5.03750741e-02,  7.94695243e-02],\n",
      "       [-2.77868006e-02,  4.85069454e-02],\n",
      "       [-9.23613980e-02,  8.07039440e-02],\n",
      "       [ 7.39331841e-02,  1.67937558e-02],\n",
      "       [-8.85640606e-02, -4.60755266e-02],\n",
      "       [ 1.00249998e-01,  1.66447158e-03],\n",
      "       [ 4.02212180e-02, -9.22799334e-02],\n",
      "       [-4.41296808e-02, -4.85856570e-02],\n",
      "       [-7.16349902e-03,  8.71897414e-02],\n",
      "       [-2.78306892e-04,  5.22836111e-02],\n",
      "       [-5.97405806e-02, -6.30953833e-02],\n",
      "       [-5.51669160e-03, -1.10420123e-01]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 0.0044645, -0.0044645], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "models = ['d1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8', 'd9', 'd10', 'd11', 'd12', 'd13', 'd14', 'd15', 'd16', 'd17', 'd18', 'd19', 'd20']\n",
    "avgWeight = FedAvg(models)\n",
    "print(avgWeight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testNewGlobal(weight):\n",
    "    \n",
    "    print('Reading Testing Data')\n",
    "    \n",
    "    TestCells = np.concatenate((TestParasitizedCells, TestUninfectedCells))\n",
    "    TestLabels = np.concatenate((TestParasitizedLabels, TestUninfectedLabels))\n",
    "    \n",
    "    \n",
    "    sTest = np.arange(TestCells.shape[0])\n",
    "    np.random.shuffle(sTest)\n",
    "    TestCells = TestCells[sTest]\n",
    "    TestLabels = TestLabels[sTest]\n",
    "    \n",
    "    num_classes=len(np.unique(TestLabels))\n",
    "    \n",
    "    (x_test) = TestCells\n",
    "    (y_test) = TestLabels\n",
    "    \n",
    "    # Since we're working on image data, we normalize data by divinding 255.\n",
    "    x_test = x_test.astype('float32')/255\n",
    "    test_len=len(x_test)\n",
    "    \n",
    "    #Doing One hot encoding as classifier has multiple classes\n",
    "    y_test=keras.utils.to_categorical(y_test,num_classes)\n",
    "    \n",
    "    #creating sequential model\n",
    "    model=Sequential()\n",
    "    model.add(Conv2D(filters=16,kernel_size=2,padding=\"same\",activation=\"relu\",input_shape=(50,50,3)))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Conv2D(filters=64,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(500,activation=\"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(2,activation=\"softmax\"))#2 represent output layer neurons \n",
    "#     model.summary()\n",
    "\n",
    "    model.set_weights(weight)\n",
    "\n",
    "    # compile the model with loss as categorical_crossentropy and using adam optimizer\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    scores = model.evaluate(x_test, y_test)\n",
    "    print(\"Loss: \", scores[0])        #Loss\n",
    "    print(\"Accuracy: \", scores[1])    #Accuracy\n",
    "\n",
    "    #Saving Model\n",
    "    model.save(\"./output.h5\")\n",
    "    return scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Testing Data\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.5879 - accuracy: 0.7133\n",
      "Loss:  0.5878175497055054\n",
      "Accuracy:  0.7065001130104065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7065001130104065"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testNewGlobal(avgWeight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataSize</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Weightage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Genesis</th>\n",
       "      <td>1382</td>\n",
       "      <td>0.652725</td>\n",
       "      <td>0.062718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d1</th>\n",
       "      <td>1061</td>\n",
       "      <td>0.671917</td>\n",
       "      <td>0.048151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2</th>\n",
       "      <td>1050</td>\n",
       "      <td>0.691291</td>\n",
       "      <td>0.047651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d3</th>\n",
       "      <td>1347</td>\n",
       "      <td>0.695999</td>\n",
       "      <td>0.061130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d4</th>\n",
       "      <td>858</td>\n",
       "      <td>0.707949</td>\n",
       "      <td>0.038938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d5</th>\n",
       "      <td>1676</td>\n",
       "      <td>0.723882</td>\n",
       "      <td>0.076061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d6</th>\n",
       "      <td>1166</td>\n",
       "      <td>0.705233</td>\n",
       "      <td>0.052916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d7</th>\n",
       "      <td>813</td>\n",
       "      <td>0.692558</td>\n",
       "      <td>0.036896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d8</th>\n",
       "      <td>1445</td>\n",
       "      <td>0.715372</td>\n",
       "      <td>0.065577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d9</th>\n",
       "      <td>1102</td>\n",
       "      <td>0.669201</td>\n",
       "      <td>0.050011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d10</th>\n",
       "      <td>1396</td>\n",
       "      <td>0.707768</td>\n",
       "      <td>0.063354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d11</th>\n",
       "      <td>1134</td>\n",
       "      <td>0.677530</td>\n",
       "      <td>0.051464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d12</th>\n",
       "      <td>1623</td>\n",
       "      <td>0.732030</td>\n",
       "      <td>0.073656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d13</th>\n",
       "      <td>820</td>\n",
       "      <td>0.680065</td>\n",
       "      <td>0.037214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d14</th>\n",
       "      <td>1041</td>\n",
       "      <td>0.710121</td>\n",
       "      <td>0.047243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d15</th>\n",
       "      <td>565</td>\n",
       "      <td>0.629187</td>\n",
       "      <td>0.025641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d16</th>\n",
       "      <td>828</td>\n",
       "      <td>0.694007</td>\n",
       "      <td>0.037577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d17</th>\n",
       "      <td>831</td>\n",
       "      <td>0.689661</td>\n",
       "      <td>0.037713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d18</th>\n",
       "      <td>521</td>\n",
       "      <td>0.669020</td>\n",
       "      <td>0.023644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d19</th>\n",
       "      <td>814</td>\n",
       "      <td>0.673366</td>\n",
       "      <td>0.036941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d20</th>\n",
       "      <td>562</td>\n",
       "      <td>0.654173</td>\n",
       "      <td>0.025505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DataSize  Accuracy  Weightage\n",
       "Genesis      1382  0.652725   0.062718\n",
       "d1           1061  0.671917   0.048151\n",
       "d2           1050  0.691291   0.047651\n",
       "d3           1347  0.695999   0.061130\n",
       "d4            858  0.707949   0.038938\n",
       "d5           1676  0.723882   0.076061\n",
       "d6           1166  0.705233   0.052916\n",
       "d7            813  0.692558   0.036896\n",
       "d8           1445  0.715372   0.065577\n",
       "d9           1102  0.669201   0.050011\n",
       "d10          1396  0.707768   0.063354\n",
       "d11          1134  0.677530   0.051464\n",
       "d12          1623  0.732030   0.073656\n",
       "d13           820  0.680065   0.037214\n",
       "d14          1041  0.710121   0.047243\n",
       "d15           565  0.629187   0.025641\n",
       "d16           828  0.694007   0.037577\n",
       "d17           831  0.689661   0.037713\n",
       "d18           521  0.669020   0.023644\n",
       "d19           814  0.673366   0.036941\n",
       "d20           562  0.654173   0.025505"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FLAccuracyDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
